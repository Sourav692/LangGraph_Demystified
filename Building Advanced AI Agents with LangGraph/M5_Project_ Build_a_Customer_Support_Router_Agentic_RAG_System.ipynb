{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NffLMDtsJFsY"
      },
      "source": [
        "# Build a Customer Support Router Agentic RAG System\n",
        "\n",
        "In this project, we will leverage the power of AI Agents and RAG Systems to build an intelligent Router Agentic RAG System to handle customer support queries using a custom knowledgebase.\n",
        "\n",
        "![](https://i.imgur.com/bLCdxCI.png)\n",
        "\n",
        "### Intelligent Router Agentic RAG System\n",
        "\n",
        "This project focuses on building an **Intelligent Router Agentic RAG System** that combines intelligent query analysis, sentiment detection, and dynamic routing with Retrieval-Augmented Generation (RAG) to handle diverse user inquiries efficiently. The workflow includes the following components:\n",
        "\n",
        "1. **Query Categorization and Sentiment Analysis**:\n",
        "   - The system uses **OpenAI GPT-4o** to analyze the user's query and determine:\n",
        "     - **Query Category**: Identifies the type of problem, such as billing, technical issues, or general queries.\n",
        "     - **User Sentiment**: Evaluates the user's sentiment (positive, neutral, or negative) to determine if escalation is needed.\n",
        "\n",
        "2. **Intelligent Routing**:\n",
        "   - Based on the **query_category** and **query_sentiment**, the system routes the query to the appropriate handling node:\n",
        "     - **Escalate to Human**: If the sentiment is negative, the query is escalated to a human for resolution.\n",
        "     - **Generate Billing Response**: Queries related to billing are routed to generate an appropriate response.\n",
        "     - **Generate Technical Response**: Technical queries are routed for a specialized technical response.\n",
        "     - **Generate General Response**: General queries are handled with context-aware responses.\n",
        "\n",
        "3. **Knowledge Base Integration (RAG)**:\n",
        "   - The system integrates with a **Knowledge Base (Vector Database)** to augment responses with relevant and accurate information.\n",
        "   - Retrieval-Augmented Generation (RAG) ensures that responses are grounded in the latest and most reliable data.\n",
        "\n",
        "4. **Escalation Mechanism**:\n",
        "   - Negative sentiment triggers an **escalation to a human**, ensuring the user receives empathetic and personalized support for critical issues.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hEI3WL328vZ"
      },
      "source": [
        "## Install OpenAI, LangGraph and LangChain dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dzjE7G_8KOUM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain==0.3.14\n",
            "  Using cached langchain-0.3.14-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting PyYAML>=5.3 (from langchain==0.3.14)\n",
            "  Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
            "Collecting SQLAlchemy<3,>=1.4 (from langchain==0.3.14)\n",
            "  Using cached sqlalchemy-2.0.40-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
            "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain==0.3.14)\n",
            "  Using cached aiohttp-3.11.18-cp312-cp312-win_amd64.whl.metadata (8.0 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.29 (from langchain==0.3.14)\n",
            "  Using cached langchain_core-0.3.58-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain==0.3.14)\n",
            "  Using cached langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting langsmith<0.3,>=0.1.17 (from langchain==0.3.14)\n",
            "  Using cached langsmith-0.2.11-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain==0.3.14) (2.2.5)\n",
            "Collecting pydantic<3.0.0,>=2.7.4 (from langchain==0.3.14)\n",
            "  Using cached pydantic-2.11.4-py3-none-any.whl.metadata (66 kB)\n",
            "Collecting requests<3,>=2 (from langchain==0.3.14)\n",
            "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain==0.3.14)\n",
            "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14)\n",
            "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14)\n",
            "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14)\n",
            "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14)\n",
            "  Using cached frozenlist-1.6.0-cp312-cp312-win_amd64.whl.metadata (16 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14)\n",
            "  Using cached multidict-6.4.3-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14)\n",
            "  Using cached propcache-0.3.1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14)\n",
            "  Using cached yarl-1.20.0-cp312-cp312-win_amd64.whl.metadata (74 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.29->langchain==0.3.14)\n",
            "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting packaging<25,>=23.2 (from langchain-core<0.4.0,>=0.3.29->langchain==0.3.14)\n",
            "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting typing-extensions>=4.7 (from langchain-core<0.4.0,>=0.3.29->langchain==0.3.14)\n",
            "  Using cached typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain==0.3.14)\n",
            "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting httpx<1,>=0.23.0 (from langsmith<0.3,>=0.1.17->langchain==0.3.14)\n",
            "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.3,>=0.1.17->langchain==0.3.14)\n",
            "  Using cached orjson-3.10.18-cp312-cp312-win_amd64.whl.metadata (43 kB)\n",
            "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.3,>=0.1.17->langchain==0.3.14)\n",
            "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting anyio (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.14)\n",
            "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting certifi (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.14)\n",
            "  Using cached certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.14)\n",
            "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting idna (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.14)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.14)\n",
            "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain==0.3.14)\n",
            "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.7.4->langchain==0.3.14)\n",
            "  Using cached pydantic_core-2.33.2-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
            "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.7.4->langchain==0.3.14)\n",
            "  Using cached typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain==0.3.14)\n",
            "  Using cached charset_normalizer-3.4.2-cp312-cp312-win_amd64.whl.metadata (36 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain==0.3.14)\n",
            "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain==0.3.14)\n",
            "  Using cached greenlet-3.2.1-cp312-cp312-win_amd64.whl.metadata (4.2 kB)\n",
            "Collecting sniffio>=1.1 (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.14)\n",
            "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Using cached langchain-0.3.14-py3-none-any.whl (1.0 MB)\n",
            "Using cached aiohttp-3.11.18-cp312-cp312-win_amd64.whl (439 kB)\n",
            "Using cached langchain_core-0.3.58-py3-none-any.whl (437 kB)\n",
            "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Using cached langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
            "Using cached langsmith-0.2.11-py3-none-any.whl (326 kB)\n",
            "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
            "Using cached multidict-6.4.3-cp312-cp312-win_amd64.whl (38 kB)\n",
            "Using cached orjson-3.10.18-cp312-cp312-win_amd64.whl (134 kB)\n",
            "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
            "Using cached pydantic-2.11.4-py3-none-any.whl (443 kB)\n",
            "Using cached pydantic_core-2.33.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
            "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Using cached charset_normalizer-3.4.2-cp312-cp312-win_amd64.whl (105 kB)\n",
            "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "Using cached sqlalchemy-2.0.40-cp312-cp312-win_amd64.whl (2.1 MB)\n",
            "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
            "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
            "Using cached yarl-1.20.0-cp312-cp312-win_amd64.whl (92 kB)\n",
            "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "Using cached certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
            "Using cached frozenlist-1.6.0-cp312-cp312-win_amd64.whl (120 kB)\n",
            "Using cached greenlet-3.2.1-cp312-cp312-win_amd64.whl (296 kB)\n",
            "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
            "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Using cached propcache-0.3.1-cp312-cp312-win_amd64.whl (44 kB)\n",
            "Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl (156 kB)\n",
            "Using cached typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "Using cached typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
            "Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
            "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: urllib3, typing-extensions, tenacity, sniffio, PyYAML, propcache, packaging, orjson, multidict, jsonpointer, idna, h11, greenlet, frozenlist, charset-normalizer, certifi, attrs, annotated-types, aiohappyeyeballs, yarl, typing-inspection, SQLAlchemy, requests, pydantic-core, jsonpatch, httpcore, anyio, aiosignal, requests-toolbelt, pydantic, httpx, aiohttp, langsmith, langchain-core, langchain-text-splitters, langchain\n",
            "\n",
            "   ----------------------------------------  0/36 [urllib3]\n",
            "   ----------------------------------------  0/36 [urllib3]\n",
            "   ----------------------------------------  0/36 [urllib3]\n",
            "   - --------------------------------------  1/36 [typing-extensions]\n",
            "   -- -------------------------------------  2/36 [tenacity]\n",
            "   ---- -----------------------------------  4/36 [PyYAML]\n",
            "   ---- -----------------------------------  4/36 [PyYAML]\n",
            "   ----- ----------------------------------  5/36 [propcache]\n",
            "  Attempting uninstall: packaging\n",
            "   ----- ----------------------------------  5/36 [propcache]\n",
            "    Found existing installation: packaging 25.0\n",
            "   ----- ----------------------------------  5/36 [propcache]\n",
            "    Uninstalling packaging-25.0:\n",
            "   ----- ----------------------------------  5/36 [propcache]\n",
            "      Successfully uninstalled packaging-25.0\n",
            "   ----- ----------------------------------  5/36 [propcache]\n",
            "   ------ ---------------------------------  6/36 [packaging]\n",
            "   ------ ---------------------------------  6/36 [packaging]\n",
            "   ------ ---------------------------------  6/36 [packaging]\n",
            "   -------- -------------------------------  8/36 [multidict]\n",
            "   ----------- ---------------------------- 10/36 [idna]\n",
            "   ----------- ---------------------------- 10/36 [idna]\n",
            "   ------------ --------------------------- 11/36 [h11]\n",
            "   ------------ --------------------------- 11/36 [h11]\n",
            "   ------------- -------------------------- 12/36 [greenlet]\n",
            "   ------------- -------------------------- 12/36 [greenlet]\n",
            "   ------------- -------------------------- 12/36 [greenlet]\n",
            "   --------------- ------------------------ 14/36 [charset-normalizer]\n",
            "   --------------- ------------------------ 14/36 [charset-normalizer]\n",
            "   --------------- ------------------------ 14/36 [charset-normalizer]\n",
            "   --------------- ------------------------ 14/36 [charset-normalizer]\n",
            "   ----------------- ---------------------- 16/36 [attrs]\n",
            "   ----------------- ---------------------- 16/36 [attrs]\n",
            "   ----------------- ---------------------- 16/36 [attrs]\n",
            "   -------------------- ------------------- 18/36 [aiohappyeyeballs]\n",
            "   --------------------- ------------------ 19/36 [yarl]\n",
            "   ---------------------- ----------------- 20/36 [typing-inspection]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ----------------------- ---------------- 21/36 [SQLAlchemy]\n",
            "   ------------------------ --------------- 22/36 [requests]\n",
            "   ------------------------ --------------- 22/36 [requests]\n",
            "   ------------------------ --------------- 22/36 [requests]\n",
            "   ------------------------- -------------- 23/36 [pydantic-core]\n",
            "   -------------------------- ------------- 24/36 [jsonpatch]\n",
            "   --------------------------- ------------ 25/36 [httpcore]\n",
            "   --------------------------- ------------ 25/36 [httpcore]\n",
            "   --------------------------- ------------ 25/36 [httpcore]\n",
            "   --------------------------- ------------ 25/36 [httpcore]\n",
            "   --------------------------- ------------ 25/36 [httpcore]\n",
            "   --------------------------- ------------ 25/36 [httpcore]\n",
            "   --------------------------- ------------ 25/36 [httpcore]\n",
            "   ---------------------------- ----------- 26/36 [anyio]\n",
            "   ---------------------------- ----------- 26/36 [anyio]\n",
            "   ---------------------------- ----------- 26/36 [anyio]\n",
            "   ---------------------------- ----------- 26/36 [anyio]\n",
            "   ---------------------------- ----------- 26/36 [anyio]\n",
            "   ---------------------------- ----------- 26/36 [anyio]\n",
            "   ---------------------------- ----------- 26/36 [anyio]\n",
            "   ---------------------------- ----------- 26/36 [anyio]\n",
            "   ------------------------------- -------- 28/36 [requests-toolbelt]\n",
            "   ------------------------------- -------- 28/36 [requests-toolbelt]\n",
            "   ------------------------------- -------- 28/36 [requests-toolbelt]\n",
            "   -------------------------------- ------- 29/36 [pydantic]\n",
            "   -------------------------------- ------- 29/36 [pydantic]\n",
            "   -------------------------------- ------- 29/36 [pydantic]\n",
            "   -------------------------------- ------- 29/36 [pydantic]\n",
            "   -------------------------------- ------- 29/36 [pydantic]\n",
            "   -------------------------------- ------- 29/36 [pydantic]\n",
            "   -------------------------------- ------- 29/36 [pydantic]\n",
            "   -------------------------------- ------- 29/36 [pydantic]\n",
            "   -------------------------------- ------- 29/36 [pydantic]\n",
            "   -------------------------------- ------- 29/36 [pydantic]\n",
            "   -------------------------------- ------- 29/36 [pydantic]\n",
            "   -------------------------------- ------- 29/36 [pydantic]\n",
            "   -------------------------------- ------- 29/36 [pydantic]\n",
            "   -------------------------------- ------- 29/36 [pydantic]\n",
            "   -------------------------------- ------- 29/36 [pydantic]\n",
            "   -------------------------------- ------- 29/36 [pydantic]\n",
            "   -------------------------------- ------- 29/36 [pydantic]\n",
            "   -------------------------------- ------- 29/36 [pydantic]\n",
            "   --------------------------------- ------ 30/36 [httpx]\n",
            "   --------------------------------- ------ 30/36 [httpx]\n",
            "   --------------------------------- ------ 30/36 [httpx]\n",
            "   --------------------------------- ------ 30/36 [httpx]\n",
            "   ---------------------------------- ----- 31/36 [aiohttp]\n",
            "   ---------------------------------- ----- 31/36 [aiohttp]\n",
            "   ---------------------------------- ----- 31/36 [aiohttp]\n",
            "   ---------------------------------- ----- 31/36 [aiohttp]\n",
            "   ---------------------------------- ----- 31/36 [aiohttp]\n",
            "   ---------------------------------- ----- 31/36 [aiohttp]\n",
            "   ---------------------------------- ----- 31/36 [aiohttp]\n",
            "   ---------------------------------- ----- 31/36 [aiohttp]\n",
            "   ---------------------------------- ----- 31/36 [aiohttp]\n",
            "   ----------------------------------- ---- 32/36 [langsmith]\n",
            "   ----------------------------------- ---- 32/36 [langsmith]\n",
            "   ----------------------------------- ---- 32/36 [langsmith]\n",
            "   ----------------------------------- ---- 32/36 [langsmith]\n",
            "   ----------------------------------- ---- 32/36 [langsmith]\n",
            "   ----------------------------------- ---- 32/36 [langsmith]\n",
            "   ------------------------------------ --- 33/36 [langchain-core]\n",
            "   ------------------------------------ --- 33/36 [langchain-core]\n",
            "   ------------------------------------ --- 33/36 [langchain-core]\n",
            "   ------------------------------------ --- 33/36 [langchain-core]\n",
            "   ------------------------------------ --- 33/36 [langchain-core]\n",
            "   ------------------------------------ --- 33/36 [langchain-core]\n",
            "   ------------------------------------ --- 33/36 [langchain-core]\n",
            "   ------------------------------------ --- 33/36 [langchain-core]\n",
            "   ------------------------------------ --- 33/36 [langchain-core]\n",
            "   ------------------------------------ --- 33/36 [langchain-core]\n",
            "   ------------------------------------ --- 33/36 [langchain-core]\n",
            "   ------------------------------------ --- 33/36 [langchain-core]\n",
            "   ------------------------------------ --- 33/36 [langchain-core]\n",
            "   ------------------------------------ --- 33/36 [langchain-core]\n",
            "   ------------------------------------ --- 33/36 [langchain-core]\n",
            "   ------------------------------------ --- 33/36 [langchain-core]\n",
            "   ------------------------------------ --- 33/36 [langchain-core]\n",
            "   ------------------------------------ --- 33/36 [langchain-core]\n",
            "   ------------------------------------ --- 33/36 [langchain-core]\n",
            "   ------------------------------------- -- 34/36 [langchain-text-splitters]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   -------------------------------------- - 35/36 [langchain]\n",
            "   ---------------------------------------- 36/36 [langchain]\n",
            "\n",
            "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.40 aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 annotated-types-0.7.0 anyio-4.9.0 attrs-25.3.0 certifi-2025.4.26 charset-normalizer-3.4.2 frozenlist-1.6.0 greenlet-3.2.1 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.10 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.14 langchain-core-0.3.58 langchain-text-splitters-0.3.8 langsmith-0.2.11 multidict-6.4.3 orjson-3.10.18 packaging-24.2 propcache-0.3.1 pydantic-2.11.4 pydantic-core-2.33.2 requests-2.32.3 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.1.2 typing-extensions-4.13.2 typing-inspection-0.4.0 urllib3-2.4.0 yarl-1.20.0\n",
            "Collecting langchain-openai==0.3.0\n",
            "  Using cached langchain_openai-0.3.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-openai==0.3.0) (0.3.58)\n",
            "Collecting openai<2.0.0,>=1.58.1 (from langchain-openai==0.3.0)\n",
            "  Using cached openai-1.77.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai==0.3.0)\n",
            "  Using cached tiktoken-0.9.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (0.2.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (4.13.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (2.11.4)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (3.10.18)\n",
            "Requirement already satisfied: requests<3,>=2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (1.0.0)\n",
            "Requirement already satisfied: anyio in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (4.9.0)\n",
            "Requirement already satisfied: certifi in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (1.0.9)\n",
            "Requirement already satisfied: idna in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (0.16.0)\n",
            "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.58.1->langchain-openai==0.3.0)\n",
            "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.58.1->langchain-openai==0.3.0)\n",
            "  Using cached jiter-0.9.0-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: sniffio in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.3.0) (1.3.1)\n",
            "Collecting tqdm>4 (from openai<2.0.0,>=1.58.1->langchain-openai==0.3.0)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain-openai==0.3.0) (2.4.0)\n",
            "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai==0.3.0)\n",
            "  Using cached regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
            "Requirement already satisfied: colorama in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.58.1->langchain-openai==0.3.0) (0.4.6)\n",
            "Using cached langchain_openai-0.3.0-py3-none-any.whl (54 kB)\n",
            "Using cached openai-1.77.0-py3-none-any.whl (662 kB)\n",
            "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Using cached jiter-0.9.0-cp312-cp312-win_amd64.whl (207 kB)\n",
            "Using cached tiktoken-0.9.0-cp312-cp312-win_amd64.whl (894 kB)\n",
            "Using cached regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Installing collected packages: tqdm, regex, jiter, distro, tiktoken, openai, langchain-openai\n",
            "\n",
            "   ---------------------------------------- 0/7 [tqdm]\n",
            "   ---------------------------------------- 0/7 [tqdm]\n",
            "   ----- ---------------------------------- 1/7 [regex]\n",
            "   ----- ---------------------------------- 1/7 [regex]\n",
            "   ---------------------- ----------------- 4/7 [tiktoken]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------- ----------- 5/7 [openai]\n",
            "   ---------------------------------- ----- 6/7 [langchain-openai]\n",
            "   ---------------------------------------- 7/7 [langchain-openai]\n",
            "\n",
            "Successfully installed distro-1.9.0 jiter-0.9.0 langchain-openai-0.3.0 openai-1.77.0 regex-2024.11.6 tiktoken-0.9.0 tqdm-4.67.1\n",
            "Collecting langchain-community==0.3.14\n",
            "  Using cached langchain_community-0.3.14-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-community==0.3.14) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-community==0.3.14) (2.0.40)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-community==0.3.14) (3.11.18)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community==0.3.14)\n",
            "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community==0.3.14)\n",
            "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.14 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-community==0.3.14) (0.3.14)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-community==0.3.14) (0.3.58)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-community==0.3.14) (0.2.11)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-community==0.3.14) (2.2.5)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community==0.3.14)\n",
            "  Using cached pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-community==0.3.14) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-community==0.3.14) (9.1.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.14) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.14) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.14) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.14) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.14) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.14) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.14) (1.20.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.14)\n",
            "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.14)\n",
            "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain<0.4.0,>=0.3.14->langchain-community==0.3.14) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain<0.4.0,>=0.3.14->langchain-community==0.3.14) (2.11.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community==0.3.14) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community==0.3.14) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community==0.3.14) (4.13.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain-community==0.3.14) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-community==0.3.14) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-community==0.3.14) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-community==0.3.14) (1.0.0)\n",
            "Requirement already satisfied: anyio in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.14) (4.9.0)\n",
            "Requirement already satisfied: certifi in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.14) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.14) (1.0.9)\n",
            "Requirement already satisfied: idna in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.14) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.14) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain-community==0.3.14) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain-community==0.3.14) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain-community==0.3.14) (0.4.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.14)\n",
            "  Using cached python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from requests<3,>=2->langchain-community==0.3.14) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from requests<3,>=2->langchain-community==0.3.14) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.3.14) (3.2.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.14)\n",
            "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.14) (1.3.1)\n",
            "Using cached langchain_community-0.3.14-py3-none-any.whl (2.5 MB)\n",
            "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "Using cached pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Using cached python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "\n",
            "   ---------------------------------------- 0/8 [python-dotenv]\n",
            "   ---------- ----------------------------- 2/8 [marshmallow]\n",
            "   -------------------- ------------------- 4/8 [typing-inspect]\n",
            "   ------------------------- -------------- 5/8 [pydantic-settings]\n",
            "   ------------------------- -------------- 5/8 [pydantic-settings]\n",
            "   ------------------------------ --------- 6/8 [dataclasses-json]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ----------------------------------- ---- 7/8 [langchain-community]\n",
            "   ---------------------------------------- 8/8 [langchain-community]\n",
            "\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.14 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.9.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n",
            "Collecting langgraph==0.2.64\n",
            "  Using cached langgraph-0.2.64-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langgraph==0.2.64) (0.3.58)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph==0.2.64)\n",
            "  Using cached langgraph_checkpoint-2.0.25-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph==0.2.64)\n",
            "  Using cached langgraph_sdk-0.1.66-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (0.2.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (4.13.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (2.11.4)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (3.0.0)\n",
            "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph==0.2.64)\n",
            "  Using cached ormsgpack-1.9.1-cp312-cp312-win_amd64.whl.metadata (44 kB)\n",
            "Requirement already satisfied: httpx>=0.25.2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.64) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.64) (3.10.18)\n",
            "Requirement already satisfied: requests<3,>=2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (1.0.0)\n",
            "Requirement already satisfied: anyio in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.64) (4.9.0)\n",
            "Requirement already satisfied: certifi in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.64) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.64) (1.0.9)\n",
            "Requirement already satisfied: idna in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.64) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.64) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.64) (1.3.1)\n",
            "Using cached langgraph-0.2.64-py3-none-any.whl (142 kB)\n",
            "Using cached langgraph_checkpoint-2.0.25-py3-none-any.whl (42 kB)\n",
            "Using cached langgraph_sdk-0.1.66-py3-none-any.whl (47 kB)\n",
            "Using cached ormsgpack-1.9.1-cp312-cp312-win_amd64.whl (125 kB)\n",
            "Installing collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph\n",
            "\n",
            "   ---------- ----------------------------- 1/4 [langgraph-sdk]\n",
            "   -------------------- ------------------- 2/4 [langgraph-checkpoint]\n",
            "   ------------------------------ --------- 3/4 [langgraph]\n",
            "   ------------------------------ --------- 3/4 [langgraph]\n",
            "   ------------------------------ --------- 3/4 [langgraph]\n",
            "   ------------------------------ --------- 3/4 [langgraph]\n",
            "   ------------------------------ --------- 3/4 [langgraph]\n",
            "   ------------------------------ --------- 3/4 [langgraph]\n",
            "   ------------------------------ --------- 3/4 [langgraph]\n",
            "   ---------------------------------------- 4/4 [langgraph]\n",
            "\n",
            "Successfully installed langgraph-0.2.64 langgraph-checkpoint-2.0.25 langgraph-sdk-0.1.66 ormsgpack-1.9.1\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain==0.3.14\n",
        "!pip install langchain-openai==0.3.0\n",
        "!pip install langchain-community==0.3.14\n",
        "!pip install langgraph==0.2.64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "f64P4sY6RtNA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain-chroma==0.2.0\n",
            "  Using cached langchain_chroma-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0 (from langchain-chroma==0.2.0)\n",
            "  Using cached chromadb-0.5.23-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting fastapi<1,>=0.95.2 (from langchain-chroma==0.2.0)\n",
            "  Using cached fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-chroma==0.2.0) (0.3.58)\n",
            "Collecting numpy<2.0.0,>=1.26.2 (from langchain-chroma==0.2.0)\n",
            "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
            "Collecting build>=1.0.3 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0) (2.11.4)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0) (0.7.6)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting posthog>=2.4.0 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached posthog-4.0.1-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0) (4.13.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached onnxruntime-1.21.1-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached opentelemetry_api-1.32.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached opentelemetry_sdk-1.32.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting tokenizers<=0.20.3,>=0.13.2 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached tokenizers-0.20.3-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
            "Collecting pypika>=0.48.9 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached pypika-0.48.9-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm>=4.65.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting importlib-resources (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting grpcio>=1.58.0 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached grpcio-1.71.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached bcrypt-4.3.0-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
            "Collecting typer>=0.9.0 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached typer-0.15.3-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0) (9.1.2)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached mmh3-5.1.0-cp312-cp312-win_amd64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0) (3.10.18)\n",
            "Requirement already satisfied: httpx>=0.27.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0) (0.28.1)\n",
            "Collecting rich>=10.11.0 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi<1,>=0.95.2->langchain-chroma==0.2.0)\n",
            "  Using cached starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-chroma==0.2.0) (0.2.11)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-chroma==0.2.0) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-chroma==0.2.0) (24.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-chroma==0.2.0) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-chroma==0.2.0) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-chroma==0.2.0) (1.0.0)\n",
            "Requirement already satisfied: anyio in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0) (4.9.0)\n",
            "Requirement already satisfied: certifi in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0) (1.0.9)\n",
            "Requirement already satisfied: idna in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from pydantic>=1.9->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from pydantic>=1.9->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from pydantic>=1.9->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-chroma==0.2.0) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-chroma==0.2.0) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0) (1.3.1)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers<=0.20.3,>=0.13.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting filelock (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: colorama in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from build>=1.0.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0) (0.4.6)\n",
            "Requirement already satisfied: six>=1.9.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0) (2.9.0.post0)\n",
            "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached google_auth-2.39.0-py2.py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached protobuf-6.30.2-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
            "Collecting sympy (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting importlib-metadata<8.7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting zipp>=3.20 (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting wrapt<2,>=1.10 (from deprecated>=1.2.6->opentelemetry-api>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached wrapt-1.17.2-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
            "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached opentelemetry_proto-1.32.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached protobuf-5.29.4-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
            "Collecting opentelemetry-semantic-conventions==0.53b1 (from opentelemetry-sdk>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached opentelemetry_instrumentation-0.53b1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting opentelemetry-util-http==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached opentelemetry_util_http-0.53b1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from posthog>=2.4.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0) (1.9.0)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0) (2.19.1)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting click>=8.0.0 (from typer>=0.9.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached httptools-0.6.4-cp312-cp312-win_amd64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in d:\\2. my workspace and notes\\1. demystify folders\\generativai_demystified\\venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0) (1.1.0)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached watchfiles-1.0.5-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached websockets-15.0.1-cp312-cp312-win_amd64.whl.metadata (7.0 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->langchain-chroma==0.2.0)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Using cached langchain_chroma-0.2.0-py3-none-any.whl (11 kB)\n",
            "Using cached chromadb-0.5.23-py3-none-any.whl (628 kB)\n",
            "Using cached fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
            "Using cached starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "Using cached tokenizers-0.20.3-cp312-none-win_amd64.whl (2.4 MB)\n",
            "Using cached huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
            "Using cached bcrypt-4.3.0-cp39-abi3-win_amd64.whl (152 kB)\n",
            "Using cached build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Using cached fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
            "Using cached grpcio-1.71.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
            "Using cached kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
            "Using cached durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Using cached google_auth-2.39.0-py2.py3-none-any.whl (212 kB)\n",
            "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
            "Using cached mmh3-5.1.0-cp312-cp312-win_amd64.whl (41 kB)\n",
            "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "Using cached onnxruntime-1.21.1-cp312-cp312-win_amd64.whl (12.3 MB)\n",
            "Using cached opentelemetry_api-1.32.1-py3-none-any.whl (65 kB)\n",
            "Using cached importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
            "Using cached Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Using cached wrapt-1.17.2-cp312-cp312-win_amd64.whl (38 kB)\n",
            "Using cached opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl (18 kB)\n",
            "Using cached opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl (18 kB)\n",
            "Using cached opentelemetry_proto-1.32.1-py3-none-any.whl (55 kB)\n",
            "Using cached googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
            "Using cached opentelemetry_sdk-1.32.1-py3-none-any.whl (118 kB)\n",
            "Using cached opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl (188 kB)\n",
            "Using cached protobuf-5.29.4-cp310-abi3-win_amd64.whl (434 kB)\n",
            "Using cached opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl (12 kB)\n",
            "Using cached opentelemetry_instrumentation-0.53b1-py3-none-any.whl (30 kB)\n",
            "Using cached opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl (16 kB)\n",
            "Using cached opentelemetry_util_http-0.53b1-py3-none-any.whl (7.3 kB)\n",
            "Using cached asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Using cached posthog-4.0.1-py2.py3-none-any.whl (92 kB)\n",
            "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
            "Using cached rich-14.0.0-py3-none-any.whl (243 kB)\n",
            "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Using cached typer-0.15.3-py3-none-any.whl (45 kB)\n",
            "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
            "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Using cached uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "Using cached httptools-0.6.4-cp312-cp312-win_amd64.whl (88 kB)\n",
            "Using cached watchfiles-1.0.5-cp312-cp312-win_amd64.whl (291 kB)\n",
            "Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
            "Using cached websockets-15.0.1-cp312-cp312-win_amd64.whl (176 kB)\n",
            "Using cached zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
            "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
            "Using cached pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Using cached pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
            "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Installing collected packages: pypika, mpmath, flatbuffers, durationpy, zipp, wrapt, websockets, websocket-client, sympy, shellingham, pyreadline3, pyproject_hooks, pyasn1, protobuf, overrides, opentelemetry-util-http, oauthlib, numpy, mmh3, mdurl, importlib-resources, httptools, grpcio, fsspec, filelock, click, cachetools, bcrypt, backoff, asgiref, watchfiles, uvicorn, starlette, rsa, requests-oauthlib, pyasn1-modules, posthog, opentelemetry-proto, markdown-it-py, importlib-metadata, humanfriendly, huggingface-hub, googleapis-common-protos, deprecated, build, tokenizers, rich, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, google-auth, fastapi, coloredlogs, typer, opentelemetry-semantic-conventions, onnxruntime, kubernetes, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb, langchain-chroma\n",
            "\n",
            "   ----------------------------------------  0/63 [pypika]\n",
            "    ---------------------------------------  1/63 [mpmath]\n",
            "    ---------------------------------------  1/63 [mpmath]\n",
            "    ---------------------------------------  1/63 [mpmath]\n",
            "    ---------------------------------------  1/63 [mpmath]\n",
            "    ---------------------------------------  1/63 [mpmath]\n",
            "    ---------------------------------------  1/63 [mpmath]\n",
            "    ---------------------------------------  1/63 [mpmath]\n",
            "    ---------------------------------------  1/63 [mpmath]\n",
            "    ---------------------------------------  1/63 [mpmath]\n",
            "    ---------------------------------------  1/63 [mpmath]\n",
            "    ---------------------------------------  1/63 [mpmath]\n",
            "    ---------------------------------------  1/63 [mpmath]\n",
            "    ---------------------------------------  1/63 [mpmath]\n",
            "    ---------------------------------------  1/63 [mpmath]\n",
            "    ---------------------------------------  1/63 [mpmath]\n",
            "   - --------------------------------------  2/63 [flatbuffers]\n",
            "   -- -------------------------------------  4/63 [zipp]\n",
            "   --- ------------------------------------  5/63 [wrapt]\n",
            "   --- ------------------------------------  6/63 [websockets]\n",
            "   --- ------------------------------------  6/63 [websockets]\n",
            "   --- ------------------------------------  6/63 [websockets]\n",
            "   --- ------------------------------------  6/63 [websockets]\n",
            "   --- ------------------------------------  6/63 [websockets]\n",
            "   --- ------------------------------------  6/63 [websockets]\n",
            "   --- ------------------------------------  6/63 [websockets]\n",
            "   --- ------------------------------------  6/63 [websockets]\n",
            "   ---- -----------------------------------  7/63 [websocket-client]\n",
            "   ---- -----------------------------------  7/63 [websocket-client]\n",
            "   ---- -----------------------------------  7/63 [websocket-client]\n",
            "   ---- -----------------------------------  7/63 [websocket-client]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  8/63 [sympy]\n",
            "   ----- ----------------------------------  9/63 [shellingham]\n",
            "   ------ --------------------------------- 10/63 [pyreadline3]\n",
            "   ------ --------------------------------- 10/63 [pyreadline3]\n",
            "   ------ --------------------------------- 10/63 [pyreadline3]\n",
            "   ------ --------------------------------- 11/63 [pyproject_hooks]\n",
            "   ------- -------------------------------- 12/63 [pyasn1]\n",
            "   ------- -------------------------------- 12/63 [pyasn1]\n",
            "   ------- -------------------------------- 12/63 [pyasn1]\n",
            "   -------- ------------------------------- 13/63 [protobuf]\n",
            "   -------- ------------------------------- 13/63 [protobuf]\n",
            "   -------- ------------------------------- 13/63 [protobuf]\n",
            "   -------- ------------------------------- 13/63 [protobuf]\n",
            "   -------- ------------------------------- 13/63 [protobuf]\n",
            "   -------- ------------------------------- 13/63 [protobuf]\n",
            "   -------- ------------------------------- 13/63 [protobuf]\n",
            "   -------- ------------------------------- 13/63 [protobuf]\n",
            "   -------- ------------------------------- 14/63 [overrides]\n",
            "   --------- ------------------------------ 15/63 [opentelemetry-util-http]\n",
            "   ---------- ----------------------------- 16/63 [oauthlib]\n",
            "   ---------- ----------------------------- 16/63 [oauthlib]\n",
            "   ---------- ----------------------------- 16/63 [oauthlib]\n",
            "   ---------- ----------------------------- 16/63 [oauthlib]\n",
            "   ---------- ----------------------------- 16/63 [oauthlib]\n",
            "   ---------- ----------------------------- 16/63 [oauthlib]\n",
            "  Attempting uninstall: numpy\n",
            "   ---------- ----------------------------- 16/63 [oauthlib]\n",
            "    Found existing installation: numpy 2.2.5\n",
            "   ---------- ----------------------------- 16/63 [oauthlib]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "    Uninstalling numpy-2.2.5:\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "      Successfully uninstalled numpy-2.2.5\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ---------- ----------------------------- 17/63 [numpy]\n",
            "   ------------ --------------------------- 19/63 [mdurl]\n",
            "   ------------ --------------------------- 20/63 [importlib-resources]\n",
            "   ------------ --------------------------- 20/63 [importlib-resources]\n",
            "   ------------- -------------------------- 22/63 [grpcio]\n",
            "   ------------- -------------------------- 22/63 [grpcio]\n",
            "   ------------- -------------------------- 22/63 [grpcio]\n",
            "   ------------- -------------------------- 22/63 [grpcio]\n",
            "   ------------- -------------------------- 22/63 [grpcio]\n",
            "   ------------- -------------------------- 22/63 [grpcio]\n",
            "   -------------- ------------------------- 23/63 [fsspec]\n",
            "   -------------- ------------------------- 23/63 [fsspec]\n",
            "   -------------- ------------------------- 23/63 [fsspec]\n",
            "   -------------- ------------------------- 23/63 [fsspec]\n",
            "   -------------- ------------------------- 23/63 [fsspec]\n",
            "   -------------- ------------------------- 23/63 [fsspec]\n",
            "   --------------- ------------------------ 24/63 [filelock]\n",
            "   --------------- ------------------------ 24/63 [filelock]\n",
            "   --------------- ------------------------ 25/63 [click]\n",
            "   --------------- ------------------------ 25/63 [click]\n",
            "   ----------------- ---------------------- 28/63 [backoff]\n",
            "   ------------------ --------------------- 29/63 [asgiref]\n",
            "   ------------------- -------------------- 30/63 [watchfiles]\n",
            "   ------------------- -------------------- 30/63 [watchfiles]\n",
            "   ------------------- -------------------- 31/63 [uvicorn]\n",
            "   ------------------- -------------------- 31/63 [uvicorn]\n",
            "   ------------------- -------------------- 31/63 [uvicorn]\n",
            "   ------------------- -------------------- 31/63 [uvicorn]\n",
            "   -------------------- ------------------- 32/63 [starlette]\n",
            "   -------------------- ------------------- 32/63 [starlette]\n",
            "   -------------------- ------------------- 32/63 [starlette]\n",
            "   -------------------- ------------------- 32/63 [starlette]\n",
            "   -------------------- ------------------- 32/63 [starlette]\n",
            "   -------------------- ------------------- 33/63 [rsa]\n",
            "   -------------------- ------------------- 33/63 [rsa]\n",
            "   -------------------- ------------------- 33/63 [rsa]\n",
            "   -------------------- ------------------- 33/63 [rsa]\n",
            "   -------------------- ------------------- 33/63 [rsa]\n",
            "   --------------------- ------------------ 34/63 [requests-oauthlib]\n",
            "   --------------------- ------------------ 34/63 [requests-oauthlib]\n",
            "   ---------------------- ----------------- 35/63 [pyasn1-modules]\n",
            "   ---------------------- ----------------- 35/63 [pyasn1-modules]\n",
            "   ---------------------- ----------------- 35/63 [pyasn1-modules]\n",
            "   ---------------------- ----------------- 35/63 [pyasn1-modules]\n",
            "   ---------------------- ----------------- 35/63 [pyasn1-modules]\n",
            "   ---------------------- ----------------- 35/63 [pyasn1-modules]\n",
            "   ---------------------- ----------------- 35/63 [pyasn1-modules]\n",
            "   ---------------------- ----------------- 35/63 [pyasn1-modules]\n",
            "   ---------------------- ----------------- 35/63 [pyasn1-modules]\n",
            "   ---------------------- ----------------- 35/63 [pyasn1-modules]\n",
            "   ---------------------- ----------------- 35/63 [pyasn1-modules]\n",
            "   ---------------------- ----------------- 35/63 [pyasn1-modules]\n",
            "   ---------------------- ----------------- 35/63 [pyasn1-modules]\n",
            "   ---------------------- ----------------- 35/63 [pyasn1-modules]\n",
            "   ---------------------- ----------------- 36/63 [posthog]\n",
            "   ---------------------- ----------------- 36/63 [posthog]\n",
            "   ---------------------- ----------------- 36/63 [posthog]\n",
            "   ----------------------- ---------------- 37/63 [opentelemetry-proto]\n",
            "   ----------------------- ---------------- 37/63 [opentelemetry-proto]\n",
            "   ------------------------ --------------- 38/63 [markdown-it-py]\n",
            "   ------------------------ --------------- 38/63 [markdown-it-py]\n",
            "   ------------------------ --------------- 38/63 [markdown-it-py]\n",
            "   ------------------------ --------------- 38/63 [markdown-it-py]\n",
            "   ------------------------ --------------- 38/63 [markdown-it-py]\n",
            "   ------------------------ --------------- 38/63 [markdown-it-py]\n",
            "   ------------------------ --------------- 38/63 [markdown-it-py]\n",
            "   ------------------------ --------------- 39/63 [importlib-metadata]\n",
            "   ------------------------ --------------- 39/63 [importlib-metadata]\n",
            "   ------------------------- -------------- 40/63 [humanfriendly]\n",
            "   ------------------------- -------------- 40/63 [humanfriendly]\n",
            "   -------------------------- ------------- 41/63 [huggingface-hub]\n",
            "   -------------------------- ------------- 41/63 [huggingface-hub]\n",
            "   -------------------------- ------------- 41/63 [huggingface-hub]\n",
            "   -------------------------- ------------- 41/63 [huggingface-hub]\n",
            "   -------------------------- ------------- 41/63 [huggingface-hub]\n",
            "   -------------------------- ------------- 41/63 [huggingface-hub]\n",
            "   -------------------------- ------------- 41/63 [huggingface-hub]\n",
            "   -------------------------- ------------- 41/63 [huggingface-hub]\n",
            "   -------------------------- ------------- 41/63 [huggingface-hub]\n",
            "   -------------------------- ------------- 41/63 [huggingface-hub]\n",
            "   -------------------------- ------------- 41/63 [huggingface-hub]\n",
            "   -------------------------- ------------- 41/63 [huggingface-hub]\n",
            "   -------------------------- ------------- 41/63 [huggingface-hub]\n",
            "   -------------------------- ------------- 41/63 [huggingface-hub]\n",
            "   -------------------------- ------------- 41/63 [huggingface-hub]\n",
            "   -------------------------- ------------- 41/63 [huggingface-hub]\n",
            "   -------------------------- ------------- 42/63 [googleapis-common-protos]\n",
            "   -------------------------- ------------- 42/63 [googleapis-common-protos]\n",
            "   -------------------------- ------------- 42/63 [googleapis-common-protos]\n",
            "   -------------------------- ------------- 42/63 [googleapis-common-protos]\n",
            "   -------------------------- ------------- 42/63 [googleapis-common-protos]\n",
            "   -------------------------- ------------- 42/63 [googleapis-common-protos]\n",
            "   -------------------------- ------------- 42/63 [googleapis-common-protos]\n",
            "   -------------------------- ------------- 42/63 [googleapis-common-protos]\n",
            "   -------------------------- ------------- 42/63 [googleapis-common-protos]\n",
            "   --------------------------- ------------ 43/63 [deprecated]\n",
            "   --------------------------- ------------ 44/63 [build]\n",
            "   --------------------------- ------------ 44/63 [build]\n",
            "   ---------------------------- ----------- 45/63 [tokenizers]\n",
            "   ----------------------------- ---------- 46/63 [rich]\n",
            "   ----------------------------- ---------- 46/63 [rich]\n",
            "   ----------------------------- ---------- 46/63 [rich]\n",
            "   ----------------------------- ---------- 46/63 [rich]\n",
            "   ----------------------------- ---------- 46/63 [rich]\n",
            "   ----------------------------- ---------- 46/63 [rich]\n",
            "   ----------------------------- ---------- 46/63 [rich]\n",
            "   ----------------------------- ---------- 46/63 [rich]\n",
            "   ----------------------------- ---------- 46/63 [rich]\n",
            "   ----------------------------- ---------- 46/63 [rich]\n",
            "   -------------------- ------ 47/63 [opentelemetry-exporter-otlp-proto-common]\n",
            "   ------------------------------ --------- 48/63 [opentelemetry-api]\n",
            "   ------------------------------ --------- 48/63 [opentelemetry-api]\n",
            "   ------------------------------ --------- 48/63 [opentelemetry-api]\n",
            "   ------------------------------- -------- 49/63 [google-auth]\n",
            "   ------------------------------- -------- 49/63 [google-auth]\n",
            "   ------------------------------- -------- 49/63 [google-auth]\n",
            "   ------------------------------- -------- 49/63 [google-auth]\n",
            "   ------------------------------- -------- 49/63 [google-auth]\n",
            "   ------------------------------- -------- 49/63 [google-auth]\n",
            "   ------------------------------- -------- 49/63 [google-auth]\n",
            "   ------------------------------- -------- 49/63 [google-auth]\n",
            "   ------------------------------- -------- 50/63 [fastapi]\n",
            "   ------------------------------- -------- 50/63 [fastapi]\n",
            "   ------------------------------- -------- 50/63 [fastapi]\n",
            "   ------------------------------- -------- 50/63 [fastapi]\n",
            "   ------------------------------- -------- 50/63 [fastapi]\n",
            "   -------------------------------- ------- 51/63 [coloredlogs]\n",
            "   -------------------------------- ------- 51/63 [coloredlogs]\n",
            "   --------------------------------- ------ 52/63 [typer]\n",
            "   --------------------------------- ------ 52/63 [typer]\n",
            "   --------------------------- ----- 53/63 [opentelemetry-semantic-conventions]\n",
            "   --------------------------- ----- 53/63 [opentelemetry-semantic-conventions]\n",
            "   --------------------------- ----- 53/63 [opentelemetry-semantic-conventions]\n",
            "   --------------------------- ----- 53/63 [opentelemetry-semantic-conventions]\n",
            "   --------------------------- ----- 53/63 [opentelemetry-semantic-conventions]\n",
            "   --------------------------- ----- 53/63 [opentelemetry-semantic-conventions]\n",
            "   --------------------------- ----- 53/63 [opentelemetry-semantic-conventions]\n",
            "   --------------------------- ----- 53/63 [opentelemetry-semantic-conventions]\n",
            "   --------------------------- ----- 53/63 [opentelemetry-semantic-conventions]\n",
            "   --------------------------- ----- 53/63 [opentelemetry-semantic-conventions]\n",
            "   --------------------------- ----- 53/63 [opentelemetry-semantic-conventions]\n",
            "   ---------------------------------- ----- 54/63 [onnxruntime]\n",
            "   ---------------------------------- ----- 54/63 [onnxruntime]\n",
            "   ---------------------------------- ----- 54/63 [onnxruntime]\n",
            "   ---------------------------------- ----- 54/63 [onnxruntime]\n",
            "   ---------------------------------- ----- 54/63 [onnxruntime]\n",
            "   ---------------------------------- ----- 54/63 [onnxruntime]\n",
            "   ---------------------------------- ----- 54/63 [onnxruntime]\n",
            "   ---------------------------------- ----- 54/63 [onnxruntime]\n",
            "   ---------------------------------- ----- 54/63 [onnxruntime]\n",
            "   ---------------------------------- ----- 54/63 [onnxruntime]\n",
            "   ---------------------------------- ----- 54/63 [onnxruntime]\n",
            "   ---------------------------------- ----- 54/63 [onnxruntime]\n",
            "   ---------------------------------- ----- 54/63 [onnxruntime]\n",
            "   ---------------------------------- ----- 54/63 [onnxruntime]\n",
            "   ---------------------------------- ----- 54/63 [onnxruntime]\n",
            "   ---------------------------------- ----- 54/63 [onnxruntime]\n",
            "   ---------------------------------- ----- 54/63 [onnxruntime]\n",
            "   ---------------------------------- ----- 54/63 [onnxruntime]\n",
            "   ---------------------------------- ----- 54/63 [onnxruntime]\n",
            "   ---------------------------------- ----- 54/63 [onnxruntime]\n",
            "   ---------------------------------- ----- 54/63 [onnxruntime]\n",
            "   ---------------------------------- ----- 54/63 [onnxruntime]\n",
            "   ---------------------------------- ----- 54/63 [onnxruntime]\n",
            "   ---------------------------------- ----- 54/63 [onnxruntime]\n",
            "   ---------------------------------- ----- 54/63 [onnxruntime]\n",
            "   ---------------------------------- ----- 54/63 [onnxruntime]\n",
            "   ---------------------------------- ----- 54/63 [onnxruntime]\n",
            "   ---------------------------------- ----- 54/63 [onnxruntime]\n",
            "   ---------------------------------- ----- 54/63 [onnxruntime]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ---------------------------------- ----- 55/63 [kubernetes]\n",
            "   ----------------------------------- ---- 56/63 [opentelemetry-sdk]\n",
            "   ----------------------------------- ---- 56/63 [opentelemetry-sdk]\n",
            "   ----------------------------------- ---- 56/63 [opentelemetry-sdk]\n",
            "   ----------------------------------- ---- 56/63 [opentelemetry-sdk]\n",
            "   ----------------------------------- ---- 56/63 [opentelemetry-sdk]\n",
            "   ---------------------------------- --- 57/63 [opentelemetry-instrumentation]\n",
            "   ---------------------------------- --- 57/63 [opentelemetry-instrumentation]\n",
            "   ---------------------------------- --- 57/63 [opentelemetry-instrumentation]\n",
            "   --------------------------- - 59/63 [opentelemetry-exporter-otlp-proto-grpc]\n",
            "   -------------------------------------- - 61/63 [chromadb]\n",
            "   -------------------------------------- - 61/63 [chromadb]\n",
            "   -------------------------------------- - 61/63 [chromadb]\n",
            "   -------------------------------------- - 61/63 [chromadb]\n",
            "   -------------------------------------- - 61/63 [chromadb]\n",
            "   -------------------------------------- - 61/63 [chromadb]\n",
            "   -------------------------------------- - 61/63 [chromadb]\n",
            "   -------------------------------------- - 61/63 [chromadb]\n",
            "   -------------------------------------- - 61/63 [chromadb]\n",
            "   -------------------------------------- - 61/63 [chromadb]\n",
            "   -------------------------------------- - 61/63 [chromadb]\n",
            "   -------------------------------------- - 61/63 [chromadb]\n",
            "   -------------------------------------- - 61/63 [chromadb]\n",
            "   -------------------------------------- - 61/63 [chromadb]\n",
            "   -------------------------------------- - 61/63 [chromadb]\n",
            "   -------------------------------------- - 61/63 [chromadb]\n",
            "   -------------------------------------- - 61/63 [chromadb]\n",
            "   -------------------------------------- - 61/63 [chromadb]\n",
            "   -------------------------------------- - 61/63 [chromadb]\n",
            "   ---------------------------------------- 63/63 [langchain-chroma]\n",
            "\n",
            "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 cachetools-5.5.2 chromadb-0.5.23 click-8.1.8 coloredlogs-15.0.1 deprecated-1.2.18 durationpy-0.9 fastapi-0.115.12 filelock-3.18.0 flatbuffers-25.2.10 fsspec-2025.3.2 google-auth-2.39.0 googleapis-common-protos-1.70.0 grpcio-1.71.0 httptools-0.6.4 huggingface-hub-0.30.2 humanfriendly-10.0 importlib-metadata-8.6.1 importlib-resources-6.5.2 kubernetes-32.0.1 langchain-chroma-0.2.0 markdown-it-py-3.0.0 mdurl-0.1.2 mmh3-5.1.0 mpmath-1.3.0 numpy-1.26.4 oauthlib-3.2.2 onnxruntime-1.21.1 opentelemetry-api-1.32.1 opentelemetry-exporter-otlp-proto-common-1.32.1 opentelemetry-exporter-otlp-proto-grpc-1.32.1 opentelemetry-instrumentation-0.53b1 opentelemetry-instrumentation-asgi-0.53b1 opentelemetry-instrumentation-fastapi-0.53b1 opentelemetry-proto-1.32.1 opentelemetry-sdk-1.32.1 opentelemetry-semantic-conventions-0.53b1 opentelemetry-util-http-0.53b1 overrides-7.7.0 posthog-4.0.1 protobuf-5.29.4 pyasn1-0.6.1 pyasn1-modules-0.4.2 pypika-0.48.9 pyproject_hooks-1.2.0 pyreadline3-3.5.4 requests-oauthlib-2.0.0 rich-14.0.0 rsa-4.9.1 shellingham-1.5.4 starlette-0.46.2 sympy-1.14.0 tokenizers-0.20.3 typer-0.15.3 uvicorn-0.34.2 watchfiles-1.0.5 websocket-client-1.8.0 websockets-15.0.1 wrapt-1.17.2 zipp-3.21.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-chroma==0.2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9c37cLnSrbg"
      },
      "source": [
        "## Enter Open AI API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cv3JzCEx_PAd"
      },
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "\n",
        "OPENAI_KEY = getpass('Enter Open AI API Key: ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T0s0um5Svfa"
      },
      "source": [
        "## Setup Environment Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "x1YSuHNF_lbh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLVgrOIgR_Z1"
      },
      "source": [
        "## Load Company Knowledge Base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mjlzx9bxR-1C",
        "outputId": "be597db9-f7f3-4f08-c5d0-0d2715949e7b"
      },
      "outputs": [],
      "source": [
        "# # or download manually from https://drive.google.com/file/d/1CWHutosAcJ6fiddQW5ogvg7NgLstZJ9j/view?usp=sharing and upload to colab or your notebook location\n",
        "# !gdown 1CWHutosAcJ6fiddQW5ogvg7NgLstZJ9j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NzAAMXyTSAH",
        "outputId": "77ca97b8-369c-43cc-97a3-dcb280e6dec3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'text': 'Question: How do I integrate your AI product with my existing CRM system? Answer: You can integrate our AI product with your CRM using our API. Refer to the API documentation available on our website for step-by-step guidance.',\n",
              "  'metadata': {'category': 'technical'}},\n",
              " {'text': 'Question: What programming languages are supported by your SDK? Answer: Our SDK supports Python, Java, and JavaScript. Additional language support is planned for future updates.',\n",
              "  'metadata': {'category': 'technical'}},\n",
              " {'text': 'Question: Can your AI models run on-premise? Answer: Yes, our AI models can be deployed on-premise. We provide deployment guides for various environments.',\n",
              "  'metadata': {'category': 'technical'}}]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "with open(\"../docs/router_agent_documents.json\", \"r\") as f:\n",
        "    knowledge_base = json.load(f)\n",
        "\n",
        "knowledge_base[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi8ULKpHEc0Z",
        "outputId": "232e9f97-108a-4e4a-e626-8420797434a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'text': 'Question: How do I escalate an unresolved issue? Answer: You can escalate unresolved issues by emailing our escalation team at escalations@example.com.',\n",
              "  'metadata': {'category': 'general'}},\n",
              " {'text': 'Question: Do you have a reseller program? Answer: Yes, we have a reseller program. Please contact our sales team for details.',\n",
              "  'metadata': {'category': 'general'}},\n",
              " {'text': 'Question: What is your policy for handling damaged hardware deliveries? Answer: If you receive damaged hardware, please report it within 48 hours to our support team. We will arrange for a replacement.',\n",
              "  'metadata': {'category': 'general'}}]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "knowledge_base[-3:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ne7fLkRTdiN",
        "outputId": "4157dad9-ef97-4d5d-849b-a156a64485a7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'category': 'technical'}, page_content='Question: How do I integrate your AI product with my existing CRM system? Answer: You can integrate our AI product with your CRM using our API. Refer to the API documentation available on our website for step-by-step guidance.'),\n",
              " Document(metadata={'category': 'technical'}, page_content='Question: What programming languages are supported by your SDK? Answer: Our SDK supports Python, Java, and JavaScript. Additional language support is planned for future updates.'),\n",
              " Document(metadata={'category': 'technical'}, page_content='Question: Can your AI models run on-premise? Answer: Yes, our AI models can be deployed on-premise. We provide deployment guides for various environments.')]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.docstore.document import Document\n",
        "from tqdm import tqdm\n",
        "\n",
        "processed_docs = []\n",
        "\n",
        "for doc in tqdm(knowledge_base):\n",
        "    metadata = doc['metadata']\n",
        "    data = doc['text']\n",
        "    processed_docs.append(Document(page_content=data,\n",
        "                                   metadata=metadata))\n",
        "\n",
        "processed_docs[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-NDea2_HAZ-"
      },
      "source": [
        "## Create Vector Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "f3Ngz9vqUGt3"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# details here: https://openai.com/blog/new-embedding-models-and-api-updates\n",
        "openai_embed_model = OpenAIEmbeddings(model='text-embedding-3-small')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "g6C6d4AkUVhs"
      },
      "outputs": [],
      "source": [
        "from langchain_chroma import Chroma\n",
        "\n",
        "kbase_db = Chroma.from_documents(documents=processed_docs,\n",
        "                                  collection_name='knowledge_base',\n",
        "                                  embedding=openai_embed_model,\n",
        "                                  # need to set the distance function to cosine else it uses euclidean by default\n",
        "                                  # check https://docs.trychroma.com/guides#changing-the-distance-function\n",
        "                                  collection_metadata={\"hnsw:space\": \"cosine\"},\n",
        "                                  persist_directory=\"./knowledge_base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-Wppf1mhUw0V"
      },
      "outputs": [],
      "source": [
        "kbase_search = kbase_db.as_retriever(search_type=\"similarity_score_threshold\",\n",
        "                                     search_kwargs={\"k\": 3, \"score_threshold\": 0.2})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryudORhuUNDb",
        "outputId": "318b8b61-4f18-48f4-8fd9-f7b77b99e824"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id='655ad67c-06b6-4ac7-bed4-0b05eb5ceba6', metadata={'category': 'general'}, page_content='Question: What is your refund policy? Answer: We offer a 30-day money-back guarantee for all our products. Please contact support to initiate a refund.'),\n",
              " Document(id='97290468-5870-4cd3-80c8-039f7d4a8473', metadata={'category': 'general'}, page_content='Question: What is your policy for handling damaged hardware deliveries? Answer: If you receive damaged hardware, please report it within 48 hours to our support team. We will arrange for a replacement.'),\n",
              " Document(id='ffba3bae-1766-419a-a38a-1f86e9aed4c8', metadata={'category': 'general'}, page_content='Question: What is your shipping policy for hardware products? Answer: We provide free shipping for orders above $500. For orders below $500, a flat shipping fee of $20 applies. Shipping typically takes 5-7 business days.')]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = 'what is your refund policy?'\n",
        "metadata_filter = {'category' : 'general'}\n",
        "# Update retriever search_kwargs dynamically\n",
        "kbase_search.search_kwargs[\"filter\"] = metadata_filter\n",
        "kbase_search.invoke(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gz6MvJyTeWQD",
        "outputId": "7181f0e3-a4a0-4cd9-e3ef-7d58d1b5aceb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No relevant docs were retrieved using the relevance score threshold 0.2\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = 'what is your refund policy'\n",
        "metadata_filter = {'category' : 'General'}\n",
        "# Update retriever search_kwargs dynamically\n",
        "kbase_search.search_kwargs[\"filter\"] = metadata_filter\n",
        "kbase_search.invoke(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeCqpNFmXGRo",
        "outputId": "c264e81d-ae66-45d7-e058-cfa1af0691af"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No relevant docs were retrieved using the relevance score threshold 0.2\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = 'what is your refund policy'\n",
        "metadata_filter = {'category' : 'technical'}\n",
        "# Update retriever search_kwargs dynamically\n",
        "kbase_search.search_kwargs[\"filter\"] = metadata_filter\n",
        "kbase_search.invoke(query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Um1WrTcJFsl"
      },
      "source": [
        "## Define the Customer Inquiry State\n",
        "\n",
        "We create a `CustomerSupportState` typed dictionary to keep track of each interaction:\n",
        "- **customer_query**: The text of the customer's question\n",
        "- **query_category**: Technical, Billing, or General (used for routing)\n",
        "- **query_sentiment**: Positive, Neutral, or Negative (used for routing)\n",
        "- **final_response**: The system's response to the customer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "N2oH7LzqJFsn"
      },
      "outputs": [],
      "source": [
        "from typing import TypedDict, Literal\n",
        "from pydantic import BaseModel\n",
        "\n",
        "class CustomerSupportState(TypedDict):\n",
        "    \"\"\"\n",
        "    customer_query: the original query from the customer.\n",
        "    query_category: the topic of the query (e.g., Technical, Billing).\n",
        "    query_sentiment: the emotional tone (e.g., Positive, Negative).\n",
        "    final_response: the system-generated response.\n",
        "    \"\"\"\n",
        "    customer_query: str\n",
        "    query_category: str\n",
        "    query_sentiment: str\n",
        "    final_response: str\n",
        "\n",
        "class QueryCategory(BaseModel):\n",
        "    categorized_topic: Literal['Technical', 'Billing', 'General']\n",
        "\n",
        "class QuerySentiment(BaseModel):\n",
        "    sentiment: Literal['Positive', 'Neutral', 'Negative']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Explain TypeDict, Literal and BaseModel\n",
        "* TypedDict: Allows you to define a dictionary with a specific schema (i.e., typed keys and values). This is a lightweight structure * used for state management in memory (not validated like Pydantic models).\n",
        "* Literal: Restricts a value to a fixed set of string options.\n",
        "* BaseModel from pydantic: Used for data validation and parsing using Python type hints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "QueryCategory(categorized_topic='Billing')"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "QueryCategory(categorized_topic='Billing')  # ✅ Valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# QueryCategory(categorized_topic='billing')    # ❌ Validation error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dL-RUuX-JFso"
      },
      "source": [
        "## Create Node Functions\n",
        "\n",
        "Each function below represents a stage in processing a customer inquiry:\n",
        "\n",
        "1. **categorize_inquiry**: Classifies the query into Technical, Billing, or General.\n",
        "2. **analyze_inquiry_sentiment**: Determines if the sentiment is Positive, Neutral, or Negative.\n",
        "3. **generate_technical_response**: Produces a response for technical issues.\n",
        "4. **generate_billing_response**: Produces a response for billing questions.\n",
        "5. **generate_general_response**: Produces a response for general queries.\n",
        "6. **escalate_to_human_agent**: Escalates the query to a human if sentiment is negative.\n",
        "7. **determine_route**: Routes the inquiry to the appropriate response node based on category and sentiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "XqvrHu8ZX2tn"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "IktZ07zDJFsp"
      },
      "outputs": [],
      "source": [
        "def categorize_inquiry(support_state: CustomerSupportState) -> CustomerSupportState:\n",
        "    \"\"\"\n",
        "    Classify the customer query into Technical, Billing, or General.\n",
        "    \"\"\"\n",
        "\n",
        "    query = support_state[\"customer_query\"]\n",
        "    ROUTE_CATEGORY_PROMPT = \"\"\"Act as a customer support agent trying to best categorize the customer query.\n",
        "                               You are an agent for an AI products and hardware company.\n",
        "\n",
        "                               Please read the customer query below and\n",
        "                               determine the best category from the following list:\n",
        "\n",
        "                               'Technical', 'Billing', or 'General'.\n",
        "\n",
        "                               Remember:\n",
        "                                - Technical queries will focus more on technical aspects like AI models, hardware, software related queries etc.\n",
        "                                - General queries will focus more on general aspects like contacting support, finding things, policies etc.\n",
        "                                - Billing queries will focus more on payment and purchase related aspects\n",
        "\n",
        "                                Return just the category name (from one of the above)\n",
        "\n",
        "                                Query:\n",
        "                                {customer_query}\n",
        "                            \"\"\"\n",
        "    prompt = ROUTE_CATEGORY_PROMPT.format(customer_query=query)\n",
        "    route_category = llm.with_structured_output(QueryCategory).invoke(prompt)\n",
        "\n",
        "    return {\n",
        "        \"query_category\": route_category.categorized_topic\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uh2L4b4YaBVp",
        "outputId": "bbb9e7c1-8f43-4817-cf17-bd1ae369fa8b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'query_category': 'Technical'}"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "categorize_inquiry({\"customer_query\": \"Do you provide pretrained models?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3CDsIqGbnNV",
        "outputId": "69551d83-ef86-4c68-9913-089390e84396"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'query_category': 'General'}"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "categorize_inquiry({\"customer_query\": \"what is your refund policy?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pa3vyedQbxin",
        "outputId": "9c4c39cf-66b6-4f28-a38a-04dfbaca688d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'query_category': 'Billing'}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "categorize_inquiry({\"customer_query\": \"what payment methods are accepted?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "8xoHBg4HZ-tV"
      },
      "outputs": [],
      "source": [
        "def analyze_inquiry_sentiment(support_state: CustomerSupportState) -> CustomerSupportState:\n",
        "    \"\"\"\n",
        "    Analyze the sentiment of the customer query as Positive, Neutral, or Negative.\n",
        "    \"\"\"\n",
        "\n",
        "    query = support_state[\"customer_query\"]\n",
        "    SENTIMENT_CATEGORY_PROMPT = \"\"\"Act as a customer support agent trying to best categorize the customer query's sentiment.\n",
        "                                   You are an agent for an AI products and hardware company.\n",
        "\n",
        "                                   Please read the customer query below,\n",
        "                                   analyze its sentiment which should be one from the following list:\n",
        "\n",
        "                                   'Positive', 'Neutral', or 'Negative'.\n",
        "\n",
        "                                   Return just the sentiment (from one of the above)\n",
        "\n",
        "                                   Query:\n",
        "                                   {customer_query}\n",
        "                                \"\"\"\n",
        "    prompt = SENTIMENT_CATEGORY_PROMPT.format(customer_query=query)\n",
        "    sentiment_category = llm.with_structured_output(QuerySentiment).invoke(prompt)\n",
        "\n",
        "    return {\n",
        "        \"query_sentiment\": sentiment_category.sentiment\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ByyxDpxd3Ht",
        "outputId": "6263a8dd-d6da-4ad0-ab8b-1b885d3d1a0c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'query_sentiment': 'Neutral'}"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "analyze_inquiry_sentiment({\"customer_query\": \"what is your refund policy?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2Q9rU7md6mm",
        "outputId": "5982749d-2612-459a-bb30-55f5a251db91"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'query_sentiment': 'Negative'}"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "analyze_inquiry_sentiment({\"customer_query\": \"what is your refund policy? I am really fed up with this product and need to refund it\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "rgss3fymfknr"
      },
      "outputs": [],
      "source": [
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from typing import Dict\n",
        "\n",
        "def generate_technical_response(support_state: CustomerSupportState) -> CustomerSupportState:\n",
        "    \"\"\"\n",
        "    Provide a technical support response by combining knowledge from the vector store and LLM.\n",
        "    \"\"\"\n",
        "    # Retrieve category and ensure it is lowercase for metadata filtering\n",
        "\n",
        "    categorized_topic = support_state[\"query_category\"]\n",
        "    query = support_state[\"customer_query\"]\n",
        "\n",
        "    # Use metadata filter for 'technical' queries\n",
        "    if categorized_topic.lower() == \"technical\":\n",
        "        metadata_filter = {\"category\": \"technical\"}\n",
        "        kbase_search.search_kwargs[\"filter\"] = metadata_filter\n",
        "\n",
        "        # Perform retrieval from VectorDB\n",
        "        relevant_docs = kbase_search.invoke(query)\n",
        "        retrieved_content = \"\\n\\n\".join(doc.page_content for doc in relevant_docs)\n",
        "\n",
        "        # Combine retrieved information into the prompt\n",
        "        prompt = ChatPromptTemplate.from_template(\n",
        "            \"\"\"\n",
        "            Craft a clear and detailed technical support response for the following customer query.\n",
        "            Use the provided knowledge base information to enrich your response.\n",
        "            In case there is no knowledge base information or you do not know the answer just say:\n",
        "\n",
        "            Apologies I was not able to answer your question, please reach out to +1-xxx-xxxx\n",
        "\n",
        "            Customer Query:\n",
        "            {customer_query}\n",
        "\n",
        "            Relevant Knowledge Base Information:\n",
        "            {retrieved_content}\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "        # Generate the final response using the LLM\n",
        "        chain = prompt | llm\n",
        "        tech_reply = chain.invoke({\n",
        "            \"customer_query\": query,\n",
        "            \"retrieved_content\": retrieved_content\n",
        "        }).content\n",
        "    else:\n",
        "        # For non-technical queries, provide a default response or a general handling\n",
        "        tech_reply = \"Apologies I was not able to answer your question, please reach out to +1-xxx-xxxx\"\n",
        "\n",
        "    # Update and return the modified support state\n",
        "    return {\n",
        "        \"final_response\": tech_reply\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVXPLD2Zgf-z",
        "outputId": "8a7f0ea6-ae21-4eef-e73d-511556c946d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'final_response': 'Apologies I was not able to answer your question, please reach out to +1-xxx-xxxx'}"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_technical_response({\"customer_query\": \"what is your refund policy?\", \"query_category\": \"General\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfrobVESgoA5",
        "outputId": "3aea83f9-e9b7-4253-ba46-e214c26f4439"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'final_response': 'Yes, we do support on-premise models. Our AI models can be deployed on-premise, and we provide comprehensive deployment guides to assist you in setting them up in various environments. If you need further assistance or specific deployment guides, please feel free to reach out to our support team. They will be more than happy to help you with any additional information or troubleshooting you might need.'}"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_technical_response({\"customer_query\": \"do you support on-prem models?\", \"query_category\": \"Technical\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Ex9O4DW7iR7S"
      },
      "outputs": [],
      "source": [
        "def generate_billing_response(support_state: CustomerSupportState) -> CustomerSupportState:\n",
        "    \"\"\"\n",
        "    Provide a billing support response by combining knowledge from the vector store and LLM.\n",
        "    \"\"\"\n",
        "    # Retrieve category and ensure it is lowercase for metadata filtering\n",
        "    categorized_topic = support_state[\"query_category\"]\n",
        "    query = support_state[\"customer_query\"]\n",
        "\n",
        "    # Use metadata filter for 'billing' queries\n",
        "    if categorized_topic.lower() == \"billing\":\n",
        "        metadata_filter = {\"category\": \"billing\"}\n",
        "        kbase_search.search_kwargs[\"filter\"] = metadata_filter\n",
        "\n",
        "        # Perform retrieval from VectorDB\n",
        "        relevant_docs = kbase_search.invoke(query)\n",
        "        retrieved_content = \"\\n\\n\".join(doc.page_content for doc in relevant_docs)\n",
        "\n",
        "        # Combine retrieved information into the prompt\n",
        "        prompt = ChatPromptTemplate.from_template(\n",
        "            \"\"\"\n",
        "            Craft a clear and detailed billing support response for the following customer query.\n",
        "            Use the provided knowledge base information to enrich your response.\n",
        "            In case there is no knowledge base information or you do not know the answer just say:\n",
        "\n",
        "            Apologies I was not able to answer your question, please reach out to +1-xxx-xxxx\n",
        "\n",
        "            Customer Query:\n",
        "            {customer_query}\n",
        "\n",
        "            Relevant Knowledge Base Information:\n",
        "            {retrieved_content}\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "        # Generate the final response using the LLM\n",
        "        chain = prompt | llm\n",
        "        billing_reply = chain.invoke({\n",
        "            \"customer_query\": query,\n",
        "            \"retrieved_content\": retrieved_content\n",
        "        }).content\n",
        "    else:\n",
        "        # For non-billing queries, provide a default response or a general handling\n",
        "        billing_reply = \"Apologies I was not able to answer your question, please reach out to +1-xxx-xxxx\"\n",
        "\n",
        "    # Update and return the modified support state\n",
        "    return {\n",
        "        \"final_response\": billing_reply\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "px5LnEH-iyRQ",
        "outputId": "4cb6b664-a1f4-4f88-c443-da6f06f2704b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'final_response': 'Thank you for reaching out with your query about payment methods. We accept the following payment methods:\\n\\n1. **Credit Cards**: You can use major credit cards to make your payments.\\n2. **PayPal**: We also support payments through PayPal for your convenience.\\n3. **Wire Transfers**: For corporate accounts, we offer the option to pay via wire transfers.\\n\\nIf you have any further questions or need assistance with your payment, please feel free to reach out.'}"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_billing_response({\"customer_query\": \"what payment methods are supported?\", \"query_category\": \"Billing\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "xTS_38PGjiKt"
      },
      "outputs": [],
      "source": [
        "def generate_general_response(support_state: CustomerSupportState) -> CustomerSupportState:\n",
        "    \"\"\"\n",
        "    Provide a general support response by combining knowledge from the vector store and LLM.\n",
        "    \"\"\"\n",
        "    # Retrieve category and ensure it is lowercase for metadata filtering\n",
        "    categorized_topic = support_state[\"query_category\"]\n",
        "    query = support_state[\"customer_query\"]\n",
        "\n",
        "    # Use metadata filter for 'general' queries\n",
        "    if categorized_topic.lower() == \"general\":\n",
        "        metadata_filter = {\"category\": \"general\"}\n",
        "        kbase_search.search_kwargs[\"filter\"] = metadata_filter\n",
        "\n",
        "        # Perform retrieval from VectorDB\n",
        "        relevant_docs = kbase_search.invoke(query)\n",
        "        retrieved_content = \"\\n\\n\".join(doc.page_content for doc in relevant_docs)\n",
        "\n",
        "        # Combine retrieved information into the prompt\n",
        "        prompt = ChatPromptTemplate.from_template(\n",
        "            \"\"\"\n",
        "            Craft a clear and detailed general support response for the following customer query.\n",
        "            Use the provided knowledge base information to enrich your response.\n",
        "            In case there is no knowledge base information or you do not know the answer just say:\n",
        "\n",
        "            Apologies I was not able to answer your question, please reach out to +1-xxx-xxxx\n",
        "\n",
        "            Customer Query:\n",
        "            {customer_query}\n",
        "\n",
        "            Relevant Knowledge Base Information:\n",
        "            {retrieved_content}\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "        # Generate the final response using the LLM\n",
        "        chain = prompt | llm\n",
        "        general_reply = chain.invoke({\n",
        "            \"customer_query\": query,\n",
        "            \"retrieved_content\": retrieved_content\n",
        "        }).content\n",
        "    else:\n",
        "        # For non-general queries, provide a default response or a general handling\n",
        "        general_reply = \"Apologies I was not able to answer your question, please reach out to +1-xxx-xxxx\"\n",
        "\n",
        "    # Update and return the modified support state\n",
        "    return {\n",
        "        \"final_response\": general_reply\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Gw2y1tqjrMS",
        "outputId": "148adb95-46e0-49e7-cbd8-c6e36f56ea46"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'final_response': 'Thank you for reaching out with your question about our refund policy. We offer a 30-day money-back guarantee for all our products. If you wish to initiate a refund, please contact our support team, and they will assist you with the process. If you have any further questions or need additional assistance, feel free to reach out.'}"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_general_response({\"customer_query\": \"what is your refund policy?\", \"query_category\": \"General\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "udRwW-sscAwl"
      },
      "outputs": [],
      "source": [
        "def escalate_to_human_agent(support_state: CustomerSupportState) -> CustomerSupportState:\n",
        "    \"\"\"\n",
        "    Escalate the query to a human agent if sentiment is negative.\n",
        "    \"\"\"\n",
        "\n",
        "    return {\n",
        "        \"final_response\": \"Apologies, we are really sorry! Someone from our team will be reaching out to your shortly!\"\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Ti3TUUiSkTHG"
      },
      "outputs": [],
      "source": [
        "def determine_route(support_state: CustomerSupportState) -> str:\n",
        "    \"\"\"\n",
        "    Route the inquiry based on sentiment and category.\n",
        "    \"\"\"\n",
        "    if support_state[\"query_sentiment\"] == \"Negative\":\n",
        "        return \"escalate_to_human_agent\"\n",
        "    elif support_state[\"query_category\"] == \"Technical\":\n",
        "        return \"generate_technical_response\"\n",
        "    elif support_state[\"query_category\"] == \"Billing\":\n",
        "        return \"generate_billing_response\"\n",
        "    else:\n",
        "        return \"generate_general_response\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QahrWKv3JFsq"
      },
      "source": [
        "## Build and Compile the Workflow\n",
        "\n",
        "We construct a LangGraph workflow with the nodes defined above:\n",
        "1. **categorize_inquiry** → **analyze_inquiry_sentiment** → **route** to the proper response node.\n",
        "2. If negative, escalate to a human agent.\n",
        "3. Otherwise, produce an appropriate response (technical, billing, or general)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "YmMiVOgqJFsr"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "# Create the graph with our typed state\n",
        "customer_support_graph = StateGraph(CustomerSupportState)\n",
        "\n",
        "# Add nodes for each function\n",
        "customer_support_graph.add_node(\"categorize_inquiry\", categorize_inquiry)\n",
        "customer_support_graph.add_node(\"analyze_inquiry_sentiment\", analyze_inquiry_sentiment)\n",
        "customer_support_graph.add_node(\"generate_technical_response\", generate_technical_response)\n",
        "customer_support_graph.add_node(\"generate_billing_response\", generate_billing_response)\n",
        "customer_support_graph.add_node(\"generate_general_response\", generate_general_response)\n",
        "customer_support_graph.add_node(\"escalate_to_human_agent\", escalate_to_human_agent)\n",
        "\n",
        "# Add edges to represent the processing flow\n",
        "customer_support_graph.add_edge(\"categorize_inquiry\", \"analyze_inquiry_sentiment\")\n",
        "customer_support_graph.add_conditional_edges(\n",
        "    \"analyze_inquiry_sentiment\",\n",
        "    determine_route,\n",
        "    [\n",
        "        \"generate_technical_response\",\n",
        "        \"generate_billing_response\",\n",
        "        \"generate_general_response\",\n",
        "        \"escalate_to_human_agent\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "# All terminal nodes lead to the END\n",
        "customer_support_graph.add_edge(\"generate_technical_response\", END)\n",
        "customer_support_graph.add_edge(\"generate_billing_response\", END)\n",
        "customer_support_graph.add_edge(\"generate_general_response\", END)\n",
        "customer_support_graph.add_edge(\"escalate_to_human_agent\", END)\n",
        "\n",
        "# Set the entry point for the workflow\n",
        "customer_support_graph.set_entry_point(\"categorize_inquiry\")\n",
        "\n",
        "# Compile the graph into a runnable agent\n",
        "memory = MemorySaver()\n",
        "compiled_support_agent = customer_support_graph.compile(checkpointer=memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Txzt11uTJFss"
      },
      "source": [
        "## Visualize the Workflow\n",
        "\n",
        "Below is a generated diagram of the workflow using Mermaid syntax. It shows how each node connects in the graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "Qt89sV4kJFst",
        "outputId": "8a05f4c6-43a8-4e07-be11-75e1feb3ba72"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import display, Image, Markdown\n",
        "\n",
        "display(Image(compiled_support_agent.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVfgP2P9JFsv"
      },
      "source": [
        "## Helper Function to Run the Workflow\n",
        "\n",
        "This function takes a customer query and runs it through our compiled workflow, returning the final results (category, sentiment, and generated response)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "O409_2mRJFsw"
      },
      "outputs": [],
      "source": [
        "def call_support_agent(agent, prompt, user_session_id, verbose=False):\n",
        "    events = agent.stream(\n",
        "        {\"customer_query\": prompt}, # initial state of the agent\n",
        "        {\"configurable\": {\"thread_id\": user_session_id}},\n",
        "        stream_mode=\"values\",\n",
        "    )\n",
        "\n",
        "    print('Running Agent. Please wait...')\n",
        "    for event in events:\n",
        "        if verbose:\n",
        "                print(event)\n",
        "\n",
        "    display(Markdown(event['final_response']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VeWUyGNJFsw"
      },
      "source": [
        "## Testing the Customer Support Workflow\n",
        "\n",
        "Let's test the workflow with some sample queries to verify categorization, sentiment analysis, and response generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZ9a53halubq",
        "outputId": "ec8462ff-9833-4c26-d0fd-1ff26f8530b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Question: How do I integrate your AI product with my existing CRM system? Answer: You can integrate our AI product with your CRM using our API. Refer to the API documentation available on our website for step-by-step guidance.',\n",
              " 'Question: What programming languages are supported by your SDK? Answer: Our SDK supports Python, Java, and JavaScript. Additional language support is planned for future updates.',\n",
              " 'Question: Can your AI models run on-premise? Answer: Yes, our AI models can be deployed on-premise. We provide deployment guides for various environments.',\n",
              " 'Question: Does your hardware support edge AI applications? Answer: Yes, our hardware is optimized for edge AI, with low-latency processing and energy-efficient designs.',\n",
              " 'Question: How do I troubleshoot issues with model performance? Answer: Start by reviewing the logs, checking resource utilization, and validating input data quality. You can also reach out to support for assistance.',\n",
              " 'Question: Can I fine-tune your AI models? Answer: Yes, our platform supports model fine-tuning using your custom datasets.',\n",
              " 'Question: What are the hardware requirements for running your AI solutions? Answer: Our AI solutions require a minimum of 16GB RAM, an Intel Core i7 processor, and an NVIDIA RTX 3060 GPU for optimal performance.',\n",
              " 'Question: Do you provide pre-trained models? Answer: Yes, we offer a range of pre-trained models for various use cases such as NLP, computer vision, and recommendation systems.',\n",
              " 'Question: How do I update the firmware on your hardware products? Answer: Firmware updates can be applied through the companion app or the firmware update tool available on our website.',\n",
              " 'Question: Is your product compatible with Kubernetes for deployment? Answer: Yes, our platform provides Kubernetes deployment templates and Helm charts for easy setup.',\n",
              " \"Question: How can I get a detailed invoice for my purchase? Answer: You can download a detailed invoice from your account dashboard under the 'Billing' section.\",\n",
              " 'Question: Do you offer any discounts for annual subscriptions? Answer: Yes, we offer a 10% discount on annual subscriptions compared to monthly billing. You can select this option during checkout.',\n",
              " 'Question: Can I change my subscription plan mid-cycle? Answer: Yes, you can upgrade or downgrade your subscription plan at any time from the account dashboard. Charges will be prorated.',\n",
              " 'Question: What payment methods do you accept? Answer: We accept credit cards, PayPal, and wire transfers for corporate accounts.',\n",
              " 'Question: Do you provide refunds for unused subscription periods? Answer: Refunds are provided based on our refund policy. Please refer to our Terms and Conditions for more details.',\n",
              " 'Question: Can I receive a consolidated bill for multiple accounts? Answer: Yes, we offer consolidated billing for enterprise customers. Please contact sales to enable this feature.',\n",
              " \"Question: How do I update my billing information? Answer: You can update your billing information from the 'Billing' section in your account dashboard.\",\n",
              " 'Question: Are there any additional fees apart from the subscription cost? Answer: There are no hidden fees. However, additional services like premium support may incur extra charges.',\n",
              " 'Question: Can I get a quote for budgeting purposes? Answer: Yes, you can request a custom quote by contacting our sales team.',\n",
              " 'Question: Do you charge taxes on the subscription? Answer: Applicable taxes are calculated based on your location and displayed during checkout.',\n",
              " 'Question: What are your working hours? Answer: Our support team is available from 9:00 AM to 6:00 PM, Monday to Friday.',\n",
              " 'Question: What is your refund policy? Answer: We offer a 30-day money-back guarantee for all our products. Please contact support to initiate a refund.',\n",
              " 'Question: What is your shipping policy for hardware products? Answer: We provide free shipping for orders above $500. For orders below $500, a flat shipping fee of $20 applies. Shipping typically takes 5-7 business days.',\n",
              " 'Question: How do I contact customer support? Answer: You can contact our support team via email at support@example.com or call us at 1-800-123-4567.',\n",
              " 'Question: Do you provide training for your AI products? Answer: Yes, we provide free online tutorials and offer paid instructor-led training sessions.',\n",
              " \"Question: Where can I find user manuals for your hardware products? Answer: User manuals are available on our website under the 'Support' section.\",\n",
              " 'Question: Can I try your software before purchasing? Answer: Yes, we offer a 14-day free trial for our software products. Visit our website to sign up.',\n",
              " 'Question: How do I escalate an unresolved issue? Answer: You can escalate unresolved issues by emailing our escalation team at escalations@example.com.',\n",
              " 'Question: Do you have a reseller program? Answer: Yes, we have a reseller program. Please contact our sales team for details.',\n",
              " 'Question: What is your policy for handling damaged hardware deliveries? Answer: If you receive damaged hardware, please report it within 48 hours to our support team. We will arrange for a replacement.']"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[item['text'] for item in knowledge_base]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "s6v7AAnFlp8S",
        "outputId": "485003c1-ade1-4bcf-ddda-90ef64f65f36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Agent. Please wait...\n",
            "{'customer_query': 'do you support pre-trained models?', 'query_category': 'Technical', 'query_sentiment': 'Neutral', 'final_response': 'Yes, we do support pre-trained models. We offer a range of pre-trained models tailored for various use cases, including natural language processing (NLP), computer vision, and recommendation systems. These models are designed to help you get started quickly and efficiently with your projects.\\n\\nAdditionally, if you need to customize these models further, our platform supports model fine-tuning using your custom datasets. This allows you to adapt the pre-trained models to better suit your specific requirements.\\n\\nIf you have any more questions or need assistance with deploying or fine-tuning these models, please feel free to reach out.'}\n",
            "{'customer_query': 'do you support pre-trained models?', 'query_category': 'Technical', 'query_sentiment': 'Neutral', 'final_response': 'Yes, we do support pre-trained models. We offer a range of pre-trained models tailored for various use cases, including natural language processing (NLP), computer vision, and recommendation systems. These models are designed to help you get started quickly and efficiently with your projects.\\n\\nAdditionally, if you need to customize these models further, our platform supports model fine-tuning using your custom datasets. This allows you to adapt the pre-trained models to better suit your specific requirements.\\n\\nIf you have any more questions or need assistance with deploying or fine-tuning these models, please feel free to reach out.'}\n",
            "{'customer_query': 'do you support pre-trained models?', 'query_category': 'Technical', 'query_sentiment': 'Neutral', 'final_response': 'Yes, we do support pre-trained models. We offer a range of pre-trained models tailored for various use cases, including natural language processing (NLP), computer vision, and recommendation systems. These models are designed to help you get started quickly and efficiently with your projects.\\n\\nAdditionally, if you need to customize these models further, our platform supports model fine-tuning using your custom datasets. This allows you to adapt the pre-trained models to better suit your specific requirements.\\n\\nIf you have any more questions or need assistance with deploying or fine-tuning these models, please feel free to reach out.'}\n",
            "{'customer_query': 'do you support pre-trained models?', 'query_category': 'Technical', 'query_sentiment': 'Neutral', 'final_response': 'Yes, we do support pre-trained models. We offer a range of pre-trained models tailored for various use cases, including natural language processing (NLP), computer vision, and recommendation systems. These models are designed to help you quickly integrate advanced AI capabilities into your projects without the need to build models from scratch.\\n\\nAdditionally, if you need to customize these models further, our platform supports model fine-tuning using your custom datasets. This allows you to adapt the pre-trained models to better suit your specific requirements.\\n\\nIf you have any more questions or need assistance with deploying or fine-tuning these models, please feel free to reach out.'}\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "Yes, we do support pre-trained models. We offer a range of pre-trained models tailored for various use cases, including natural language processing (NLP), computer vision, and recommendation systems. These models are designed to help you quickly integrate advanced AI capabilities into your projects without the need to build models from scratch.\n",
              "\n",
              "Additionally, if you need to customize these models further, our platform supports model fine-tuning using your custom datasets. This allows you to adapt the pre-trained models to better suit your specific requirements.\n",
              "\n",
              "If you have any more questions or need assistance with deploying or fine-tuning these models, please feel free to reach out."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "uid = 'jim001'\n",
        "query = \"do you support pre-trained models?\"\n",
        "call_support_agent(agent=compiled_support_agent,\n",
        "                   prompt=query,\n",
        "                   user_session_id=uid,\n",
        "                   verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "id": "H4624wCxJFsx",
        "outputId": "e28b266b-711d-4e90-b8b5-5f4bb191b94b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Agent. Please wait...\n",
            "{'customer_query': 'how do I get my invoice?', 'query_category': 'Technical', 'query_sentiment': 'Neutral', 'final_response': 'Yes, we do support pre-trained models. We offer a range of pre-trained models tailored for various use cases, including natural language processing (NLP), computer vision, and recommendation systems. These models are designed to help you quickly integrate advanced AI capabilities into your projects without the need to build models from scratch.\\n\\nAdditionally, if you need to customize these models further, our platform supports model fine-tuning using your custom datasets. This allows you to adapt the pre-trained models to better suit your specific requirements.\\n\\nIf you have any more questions or need assistance with deploying or fine-tuning these models, please feel free to reach out.'}\n",
            "{'customer_query': 'how do I get my invoice?', 'query_category': 'Billing', 'query_sentiment': 'Neutral', 'final_response': 'Yes, we do support pre-trained models. We offer a range of pre-trained models tailored for various use cases, including natural language processing (NLP), computer vision, and recommendation systems. These models are designed to help you quickly integrate advanced AI capabilities into your projects without the need to build models from scratch.\\n\\nAdditionally, if you need to customize these models further, our platform supports model fine-tuning using your custom datasets. This allows you to adapt the pre-trained models to better suit your specific requirements.\\n\\nIf you have any more questions or need assistance with deploying or fine-tuning these models, please feel free to reach out.'}\n",
            "{'customer_query': 'how do I get my invoice?', 'query_category': 'Billing', 'query_sentiment': 'Neutral', 'final_response': 'Yes, we do support pre-trained models. We offer a range of pre-trained models tailored for various use cases, including natural language processing (NLP), computer vision, and recommendation systems. These models are designed to help you quickly integrate advanced AI capabilities into your projects without the need to build models from scratch.\\n\\nAdditionally, if you need to customize these models further, our platform supports model fine-tuning using your custom datasets. This allows you to adapt the pre-trained models to better suit your specific requirements.\\n\\nIf you have any more questions or need assistance with deploying or fine-tuning these models, please feel free to reach out.'}\n",
            "{'customer_query': 'how do I get my invoice?', 'query_category': 'Billing', 'query_sentiment': 'Neutral', 'final_response': \"Thank you for reaching out with your query on obtaining your invoice. You can easily download a detailed invoice by accessing your account dashboard. Once logged in, navigate to the 'Billing' section where you will find the option to view and download your invoices. If you encounter any issues or need further assistance, please feel free to reach out.\"}\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "Thank you for reaching out with your query on obtaining your invoice. You can easily download a detailed invoice by accessing your account dashboard. Once logged in, navigate to the 'Billing' section where you will find the option to view and download your invoices. If you encounter any issues or need further assistance, please feel free to reach out."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "query = \"how do I get my invoice?\"\n",
        "call_support_agent(agent=compiled_support_agent,\n",
        "                   prompt=query,\n",
        "                   user_session_id=uid,\n",
        "                   verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "LIPGRwMJn5-q",
        "outputId": "fa378fd9-eecb-4d11-dbb6-3d11469ba809"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Agent. Please wait...\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "Thank you for reaching out with your query about our shipping policy. For hardware products, we offer free shipping on orders over $500. If your order is below $500, a flat shipping fee of $20 will be applied. Typically, shipping takes between 5-7 business days. If you have any further questions or need assistance, feel free to contact our support team."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "query = \"Can you tell me about your shipping policy?\"\n",
        "call_support_agent(agent=compiled_support_agent,\n",
        "                   prompt=query,\n",
        "                   user_session_id=uid,\n",
        "                   verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "id": "FNspMHcJoBBx",
        "outputId": "b977019c-3823-473f-85da-e4aa87f5404a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Agent. Please wait...\n",
            "{'customer_query': \"I'm fed up with this faulty hardware, I need a refund\", 'query_category': 'General', 'query_sentiment': 'Neutral', 'final_response': 'Thank you for reaching out with your query about our shipping policy. For hardware products, we offer free shipping on orders over $500. If your order is below $500, a flat shipping fee of $20 will be applied. Typically, shipping takes between 5-7 business days. If you have any further questions or need assistance, feel free to contact our support team.'}\n",
            "{'customer_query': \"I'm fed up with this faulty hardware, I need a refund\", 'query_category': 'Billing', 'query_sentiment': 'Neutral', 'final_response': 'Thank you for reaching out with your query about our shipping policy. For hardware products, we offer free shipping on orders over $500. If your order is below $500, a flat shipping fee of $20 will be applied. Typically, shipping takes between 5-7 business days. If you have any further questions or need assistance, feel free to contact our support team.'}\n",
            "{'customer_query': \"I'm fed up with this faulty hardware, I need a refund\", 'query_category': 'Billing', 'query_sentiment': 'Negative', 'final_response': 'Thank you for reaching out with your query about our shipping policy. For hardware products, we offer free shipping on orders over $500. If your order is below $500, a flat shipping fee of $20 will be applied. Typically, shipping takes between 5-7 business days. If you have any further questions or need assistance, feel free to contact our support team.'}\n",
            "{'customer_query': \"I'm fed up with this faulty hardware, I need a refund\", 'query_category': 'Billing', 'query_sentiment': 'Negative', 'final_response': 'Apologies, we are really sorry! Someone from our team will be reaching out to your shortly!'}\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "Apologies, we are really sorry! Someone from our team will be reaching out to your shortly!"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "query = \"I'm fed up with this faulty hardware, I need a refund\"\n",
        "call_support_agent(agent=compiled_support_agent,\n",
        "                   prompt=query,\n",
        "                   user_session_id=uid,\n",
        "                   verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "id": "BMzoQZsBNY9n",
        "outputId": "1649789d-7ee2-4fc2-a487-ca64b2705674"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Agent. Please wait...\n",
            "{'customer_query': 'What are your working hours?', 'query_category': 'General', 'query_sentiment': 'Neutral', 'final_response': 'Apologies I was not able to answer your question, please reach out to +1-xxx-xxxx'}\n",
            "{'customer_query': 'What are your working hours?', 'query_category': 'General', 'query_sentiment': 'Neutral', 'final_response': 'Apologies I was not able to answer your question, please reach out to +1-xxx-xxxx'}\n",
            "{'customer_query': 'What are your working hours?', 'query_category': 'General', 'query_sentiment': 'Neutral', 'final_response': 'Apologies I was not able to answer your question, please reach out to +1-xxx-xxxx'}\n",
            "{'customer_query': 'What are your working hours?', 'query_category': 'General', 'query_sentiment': 'Neutral', 'final_response': \"Our support team is available from 9:00 AM to 6:00 PM, Monday to Friday. If you have any further questions or need assistance outside of these hours, please feel free to reach out to us via email at support@example.com or call us at 1-800-123-4567. We're here to help!\"}\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "Our support team is available from 9:00 AM to 6:00 PM, Monday to Friday. If you have any further questions or need assistance outside of these hours, please feel free to reach out to us via email at support@example.com or call us at 1-800-123-4567. We're here to help!"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "query = \"What are your working hours?\"\n",
        "call_support_agent(agent=compiled_support_agent,\n",
        "                   prompt=query,\n",
        "                   user_session_id=uid,\n",
        "                   verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Agent. Please wait...\n",
            "{'customer_query': 'What have I asked you till now', 'query_category': 'General', 'query_sentiment': 'Neutral', 'final_response': \"Our support team is available from 9:00 AM to 6:00 PM, Monday to Friday. If you have any further questions or need assistance outside of these hours, please feel free to reach out to us via email at support@example.com or call us at 1-800-123-4567. We're here to help!\"}\n",
            "{'customer_query': 'What have I asked you till now', 'query_category': 'General', 'query_sentiment': 'Neutral', 'final_response': \"Our support team is available from 9:00 AM to 6:00 PM, Monday to Friday. If you have any further questions or need assistance outside of these hours, please feel free to reach out to us via email at support@example.com or call us at 1-800-123-4567. We're here to help!\"}\n",
            "{'customer_query': 'What have I asked you till now', 'query_category': 'General', 'query_sentiment': 'Neutral', 'final_response': \"Our support team is available from 9:00 AM to 6:00 PM, Monday to Friday. If you have any further questions or need assistance outside of these hours, please feel free to reach out to us via email at support@example.com or call us at 1-800-123-4567. We're here to help!\"}\n",
            "{'customer_query': 'What have I asked you till now', 'query_category': 'General', 'query_sentiment': 'Neutral', 'final_response': 'Apologies I was not able to answer your question, please reach out to +1-xxx-xxxx'}\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "Apologies I was not able to answer your question, please reach out to +1-xxx-xxxx"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "query = \"What have I asked you till now\"\n",
        "call_support_agent(agent=compiled_support_agent,\n",
        "                   prompt=query,\n",
        "                   user_session_id=uid,\n",
        "                   verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
