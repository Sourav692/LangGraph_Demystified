{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, Annotated, List, Sequence\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, BaseMessage\n",
    "import operator\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# 1. First, let's write tests for our state structure\n",
    "class CustomerState(TypedDict):\n",
    "    \"\"\"State for customer support workflow\"\"\"\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    intent: str\n",
    "    status: str\n",
    "\n",
    "def test_state_structure():\n",
    "    \"\"\"Test that our state structure works as expected\"\"\"\n",
    "    state = {\n",
    "        \"messages\": [HumanMessage(content=\"Where is my order #12345?\")],\n",
    "        \"intent\": \"\",\n",
    "        \"status\": \"\"\n",
    "    }\n",
    "    assert isinstance(state[\"messages\"][0], BaseMessage)\n",
    "    assert isinstance(state[\"intent\"], str)\n",
    "    assert isinstance(state[\"status\"], str)\n",
    "\n",
    "# 2. Intent Classification Node with LLM\n",
    "intent_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a customer support intent classifier. \n",
    "    Classify the user query into one of these intents: check_order, product_inquiry, \n",
    "    escalate, or unknown. Respond with just the intent.\"\"\"),\n",
    "    (\"human\", \"{query}\")\n",
    "])\n",
    "\n",
    "def test_intent_classifier_node():\n",
    "    \"\"\"Test the intent classifier node\"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-4-mini\")\n",
    "    state = {\n",
    "        \"messages\": [HumanMessage(content=\"Where is my order #12345?\")],\n",
    "        \"intent\": \"\",\n",
    "        \"status\": \"\"\n",
    "    }\n",
    "    result = intent_classifier_node(state)\n",
    "    assert result[\"intent\"] in [\"check_order\", \"product_inquiry\", \"escalate\", \"unknown\"]\n",
    "\n",
    "def intent_classifier_node(state: CustomerState):\n",
    "    \"\"\"Classify customer intent using LLM\"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    classifier_chain = intent_prompt | llm\n",
    "    query = state[\"messages\"][-1].content\n",
    "    intent = classifier_chain.invoke({\"query\": query}).content.strip().lower()\n",
    "    state[\"intent\"] = intent\n",
    "    return state\n",
    "\n",
    "# 3. Order Status Node\n",
    "order_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a customer service agent checking order status.\n",
    "    Available orders: #12345 (shipped), #67890 (processing).\n",
    "    If the order number is not found, apologize and provide support options.\"\"\"),\n",
    "    (\"human\", \"{query}\")\n",
    "])\n",
    "\n",
    "def test_order_status_node():\n",
    "    \"\"\"Test the order status node\"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    state = {\n",
    "        \"messages\": [HumanMessage(content=\"Where is my order #12345?\")],\n",
    "        \"intent\": \"check_order\",\n",
    "        \"status\": \"\"\n",
    "    }\n",
    "    result = order_status_node(state)\n",
    "    assert len(result[\"messages\"]) > 1  # Original message plus response\n",
    "    assert \"shipped\" in result[\"messages\"][-1].content.lower()\n",
    "\n",
    "def order_status_node(state: CustomerState):\n",
    "    \"\"\"Handle order status queries using LLM\"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    order_chain = order_prompt | llm\n",
    "    query = state[\"messages\"][-1].content\n",
    "    response = order_chain.invoke({\"query\": query})\n",
    "    state[\"messages\"].append(response)\n",
    "    return state\n",
    "\n",
    "# 4. Product Inquiry Node\n",
    "product_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a product information specialist.\n",
    "    Products: wireless headphones (20-hour battery, noise cancellation),\n",
    "    smartwatch (fitness tracking, heart rate monitoring).\n",
    "    For unknown products, apologize and offer to connect with a specialist.\"\"\"),\n",
    "    (\"human\", \"{query}\")\n",
    "])\n",
    "\n",
    "def test_product_inquiry_node():\n",
    "    \"\"\"Test the product inquiry node\"\"\"\n",
    "    state = {\n",
    "        \"messages\": [HumanMessage(content=\"Tell me about wireless headphones\")],\n",
    "        \"intent\": \"product_inquiry\",\n",
    "        \"status\": \"\"\n",
    "    }\n",
    "    result = product_inquiry_node(state)\n",
    "    assert len(result[\"messages\"]) > 1\n",
    "    assert \"battery\" in result[\"messages\"][-1].content.lower()\n",
    "\n",
    "def product_inquiry_node(state: CustomerState):\n",
    "    \"\"\"Handle product inquiries using LLM\"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    product_chain = product_prompt | llm\n",
    "    query = state[\"messages\"][-1].content\n",
    "    response = product_chain.invoke({\"query\": query})\n",
    "    state[\"messages\"].append(response)\n",
    "    return state\n",
    "\n",
    "# 5. Complete Workflow\n",
    "def test_complete_workflow():\n",
    "    \"\"\"Test the complete customer support workflow\"\"\"\n",
    "    workflow = build_support_workflow()\n",
    "    \n",
    "    # Test order status query\n",
    "    result = workflow.invoke({\n",
    "        \"messages\": [HumanMessage(content=\"Where is my order #12345?\")],\n",
    "        \"intent\": \"\",\n",
    "        \"status\": \"\"\n",
    "    })\n",
    "    assert \"shipped\" in result[\"messages\"][-1].content.lower()\n",
    "    \n",
    "    # Test product inquiry\n",
    "    result = workflow.invoke({\n",
    "        \"messages\": [HumanMessage(content=\"Tell me about wireless headphones\")],\n",
    "        \"intent\": \"\",\n",
    "        \"status\": \"\"\n",
    "    })\n",
    "    assert \"battery\" in result[\"messages\"][-1].content.lower()\n",
    "\n",
    "def build_support_workflow():\n",
    "    \"\"\"Build the complete customer support workflow\"\"\"\n",
    "    # Initialize graph with our state\n",
    "    workflow = StateGraph(CustomerState)\n",
    "    \n",
    "    # Add nodes\n",
    "    workflow.add_node(\"intent_classifier\", intent_classifier_node)\n",
    "    workflow.add_node(\"order_status\", order_status_node)\n",
    "    workflow.add_node(\"product_inquiry\", product_inquiry_node)\n",
    "    \n",
    "    # Define routing logic\n",
    "    def route_by_intent(state):\n",
    "        return state[\"intent\"]\n",
    "    \n",
    "    # Add edges\n",
    "    workflow.add_edge(START, \"intent_classifier\")\n",
    "    workflow.add_conditional_edges(\n",
    "        \"intent_classifier\",\n",
    "        route_by_intent,\n",
    "        {\n",
    "            \"check_order\": \"order_status\",\n",
    "            \"product_inquiry\": \"product_inquiry\"\n",
    "        }\n",
    "    )\n",
    "    workflow.add_edge(\"order_status\", END)\n",
    "    workflow.add_edge(\"product_inquiry\", END)\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# 6. Interactive Testing\n",
    "def main():\n",
    "    \"\"\"Run interactive customer support agent\"\"\"\n",
    "    workflow = build_support_workflow()\n",
    "    \n",
    "    print(\"Customer Support AI (type 'quit' to exit)\")\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"\\nCustomer: \")\n",
    "            if query.lower() == 'quit':\n",
    "                break\n",
    "            \n",
    "            # Initialize state with proper structure\n",
    "            initial_state = {\n",
    "                \"messages\": [HumanMessage(content=query)],\n",
    "                \"intent\": \"\",\n",
    "                \"status\": \"\"\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                result = workflow.invoke(initial_state)\n",
    "                # Safely access the last message's content\n",
    "                if result and \"messages\" in result and len(result[\"messages\"]) > 0:\n",
    "                    print(f\"Agent: {result['messages'][-1].content}\")\n",
    "                else:\n",
    "                    print(\"Agent: I apologize, but I'm having trouble processing that request. Please try again.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Agent: I apologize, but I encountered an error. Please try rephrasing your question.\")\n",
    "                print(f\"Debug: {str(e)}\")\n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nGoodbye!\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {str(e)}\")\n",
    "            print(\"Please try again.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
