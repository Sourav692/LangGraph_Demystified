{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import TypedDict, Annotated, List, Sequence\n",
    "import operator\n",
    "from langchain_core.messages import BaseMessage, AIMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test_intent_classifier():\n",
    "    \"\"\"Test the intent classifier node\"\"\"\n",
    "    state = {\n",
    "        \"messages\": [HumanMessage(content=\"Where is my order #12345?\")],\n",
    "        \"intent\": \"\",\n",
    "        \"status\": \"\"\n",
    "    }\n",
    "    result = intent_classifier_node(state)\n",
    "    assert result[\"intent\"] == IntentEnum.CHECK_ORDER\n",
    "\n",
    "class CustomerState(TypedDict):\n",
    "    \"\"\"State for customer support workflow\"\"\"\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    intent: str\n",
    "    status: str\n",
    "\n",
    "\n",
    "def intent_classifier_node(state: CustomerState):\n",
    "    \"\"\"Classify customer intent using LLM\"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    classifier_chain = intent_prompt | llm\n",
    "    query = state[\"messages\"][-1].content\n",
    "    intent = classifier_chain.invoke({\"query\": query}).content.strip().lower()\n",
    "    state[\"intent\"] = intent\n",
    "    return state\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "class IntentEnum(str, Enum):\n",
    "    CHECK_ORDER = \"check_order\"\n",
    "    PRODUCT_INQUIRY = \"product_inquiry\"\n",
    "    ESCALATE = \"escalate\"\n",
    "    UNKNOWN = \"unknown\"\n",
    "\n",
    "intent_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a customer support intent classifier. \n",
    "    Classify the user query into one of these intents: check_order, product_inquiry, \n",
    "    escalate, or unknown. Respond with just the intent.\"\"\"),\n",
    "    (\"human\", \"{query}\")\n",
    "])\n",
    "\n",
    "def test_order_status():\n",
    "    \"\"\"Test the order status node\"\"\"\n",
    "    state = {\n",
    "        \"messages\": [HumanMessage(content=\"Where is my order #12345?\")],\n",
    "        \"intent\": IntentEnum.CHECK_ORDER,\n",
    "        \"status\": \"\"\n",
    "    }\n",
    "    result = order_status_node(state)\n",
    "    response_text = result[\"messages\"][-1].content.lower()\n",
    "    assert \"shipped\" in response_text or \"processing\" in response_text\n",
    "\n",
    "def order_status_node(state: CustomerState):\n",
    "    \"\"\"Handle order status queries using LLM\"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    order_chain = order_prompt | llm\n",
    "    query = state[\"messages\"][-1].content\n",
    "    response = order_chain.invoke({\"query\": query})\n",
    "    state[\"messages\"].append(AIMessage(content=response.content))\n",
    "    return state\n",
    "\n",
    "order_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a customer service agent checking order status.\n",
    "    Available orders: #12345 (shipped), #67890 (processing).\n",
    "    If the order number is not found, apologize and provide support options.\"\"\")\n",
    "])\n",
    "\n",
    "def product_inquiry_node(state: CustomerState):\n",
    "    \"\"\"Handle product inquiries using LLM\"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    product_chain = product_prompt | llm\n",
    "    query = state[\"messages\"][-1].content\n",
    "    response = product_chain.invoke({\"query\": query})\n",
    "    state[\"messages\"].append(AIMessage(content=response.content))\n",
    "    return state\n",
    "\n",
    "product_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a product information specialist.\n",
    "    Products: wireless headphones (20-hour battery, noise cancellation),\n",
    "    smartwatch (fitness tracking, heart rate monitoring).\n",
    "    For unknown products, apologize and offer to connect with a specialist.\"\"\"),])\n",
    "\n",
    "\n",
    "def test_general_chat():\n",
    "    \"\"\"Test general conversation handling\"\"\"\n",
    "    state = {\n",
    "        \"messages\": [HumanMessage(content=\"Hello, Iâ€™m James\")],\n",
    "        \"intent\": IntentEnum.GENERAL_CHAT,\n",
    "        \"status\": \"\"\n",
    "    }\n",
    "    result = general_chat_node(state)\n",
    "    response_text = result[\"messages\"][-1].content.lower()\n",
    "    assert \"nice to meet you\" in response_text and \"james\" in response_text\n",
    "\n",
    "def general_chat_node(state: CustomerState):\n",
    "    \"\"\"Handle general conversation and queries\"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    chat_chain = general_chat_prompt | llm\n",
    "    query = state[\"messages\"][-1].content\n",
    "    response = chat_chain.invoke({\"query\": query})\n",
    "    state[\"messages\"].append(AIMessage(content=response.content))\n",
    "    return state\n",
    "\n",
    "general_chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"You are a helpful assistant.\")\n",
    "])\n",
    "\n",
    "def test_complete_workflow():\n",
    "    \"\"\"Test the complete customer support workflow\"\"\"\n",
    "    workflow = build_support_workflow()\n",
    "\n",
    "    # Test order status\n",
    "    state = {\"messages\": [HumanMessage(content=\"Where is my order #12345?\")]}\n",
    "    result = workflow.invoke(state)\n",
    "    assert \"shipped\" in result[\"messages\"][-1].content.lower()\n",
    "\n",
    "    # Test product inquiry\n",
    "    state = {\"messages\": [HumanMessage(content=\"Tell me about wireless headphones\")]}\n",
    "    result = workflow.invoke(state)\n",
    "    assert \"wireless headphones\" in result[\"messages\"][-1].content.lower()\n",
    "\n",
    "    # Test general chat\n",
    "    state = {\"messages\": [HumanMessage(content=\"My name is James\")]}\n",
    "    result = workflow.invoke(state)\n",
    "    assert \"nice to meet you\" in result[\"messages\"][-1].content.lower()\n",
    "\n",
    "def build_support_workflow():\n",
    "    \"\"\"Build the complete customer support workflow\"\"\"\n",
    "    workflow = StateGraph(CustomerState)\n",
    "    workflow.add_node(\"intent_classifier\", intent_classifier_node)\n",
    "    workflow.add_node(\"order_status\", order_status_node)\n",
    "    workflow.add_node(\"product_inquiry\", product_inquiry_node)\n",
    "    workflow.add_node(\"general_chat\", general_chat_node)\n",
    "    workflow.add_edge(START, \"intent_classifier\")\n",
    "    workflow.add_edge(\"intent_classifier\", \"order_status\")\n",
    "    workflow.add_edge(\"intent_classifier\", \"product_inquiry\")\n",
    "    workflow.add_edge(\"intent_classifier\", \"general_chat\")\n",
    "    workflow.add_edge(\"order_status\", END)\n",
    "    workflow.add_edge(\"product_inquiry\", END)\n",
    "    workflow.add_edge(\"general_chat\", END)\n",
    "    return workflow.compile()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
