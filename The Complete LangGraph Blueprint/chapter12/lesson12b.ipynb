{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, TypedDict\n",
    "from langchain.schema import Document\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from display_graph import display_graph\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pprint import pprint\n",
    "\n",
    "# Step 1: Load and prepare documents\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\"\n",
    "]\n",
    "\n",
    "# Load and split documents\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=250, chunk_overlap=0)\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add to vectorstore\n",
    "vectorstore = Chroma.from_documents(doc_splits, collection_name=\"crag-chroma\", embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Step 2: Define Graders and Relevance Model\n",
    "class GradeDocuments(BaseModel):\n",
    "    binary_score: str = Field(description=\"Documents are relevant to the question, 'yes' or 'no'\")\n",
    "\n",
    "retrieval_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a grader assessing if a document is relevant to a user's question.\n",
    "Document: {document} \n",
    "Question: {question}\n",
    "Is the document relevant? Answer 'yes' or 'no'.\n",
    "\"\"\")\n",
    "\n",
    "retrieval_grader = retrieval_prompt | ChatOpenAI(model=\"gpt-4o-mini\", temperature=0).with_structured_output(GradeDocuments)\n",
    "\n",
    "# Step 3: Query Re-writer\n",
    "class ImproveQuestion(BaseModel):\n",
    "    improved_question: str = Field(description=\"Formulate an improved question.\")\n",
    "\n",
    "re_write_prompt = ChatPromptTemplate.from_template(\n",
    "   \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
    ")\n",
    "query_rewriter = re_write_prompt | ChatOpenAI(model=\"gpt-4o-mini\", temperature=0).with_structured_output(ImproveQuestion)\n",
    "\n",
    "# Define prompt template\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Use the following context to answer the question:\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\n",
    "\"\"\")\n",
    "rag_chain =  prompt | ChatOpenAI(model=\"gpt-4o-mini\", temperature=0) | StrOutputParser()\n",
    "\n",
    "\n",
    "# Define CRAG State\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    generation: str\n",
    "    web_search: str\n",
    "    documents: List[str]\n",
    "\n",
    "# Step 4: Define Workflow Nodes\n",
    "def retrieve(state):\n",
    "    question = state[\"question\"]\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "def grade_documents(state):\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    filtered_docs = []\n",
    "    web_search_needed = \"No\"\n",
    "    for doc in documents:\n",
    "        grade = retrieval_grader.invoke({\"question\": question, \"document\": doc.page_content}).binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(doc)\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            web_search_needed = \"Yes\"\n",
    "    return {\"documents\": filtered_docs, \"question\": question, \"web_search\": web_search_needed}\n",
    "\n",
    "def transform_query(state):\n",
    "    question = state[\"question\"]\n",
    "    rewritten_question = query_rewriter.invoke({\"question\": question})\n",
    "    return {\"question\": rewritten_question.improved_question, \"documents\": state[\"documents\"]}\n",
    "\n",
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    Web search based on the re-phrased question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with appended web results\n",
    "    \"\"\"\n",
    "    print(\"---WEB SEARCH---\")\n",
    "   \n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    pprint(question+\"\\n\")\n",
    "    # Perform web search using TavilySearchResults and extract only the 'content' field for Document\n",
    "    search_results = TavilySearchResults(k=3).invoke({\"query\": question})\n",
    "    \n",
    "    # Process results to create Document objects only with page_content\n",
    "    web_documents = [\n",
    "        Document(page_content=result[\"content\"]) for result in search_results if \"content\" in result\n",
    "    ]\n",
    "    \n",
    "    # Append web search results to the existing documents\n",
    "    documents.extend(web_documents)\n",
    "\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "def generate(state):\n",
    "    generation = rag_chain.invoke({\"context\": state[\"documents\"], \"question\": state[\"question\"]})\n",
    "    return {\"generation\": generation}\n",
    "\n",
    "# Step 5: Define Decision-Making Logic\n",
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or re-generate a question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    state[\"question\"]\n",
    "    web_search = state[\"web_search\"]\n",
    "    state[\"documents\"]\n",
    "\n",
    "    if web_search == \"Yes\":\n",
    "        # All documents have been filtered check_relevance\n",
    "        # We will re-generate a new query\n",
    "        print(\n",
    "            \"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\"\n",
    "        )\n",
    "        return \"transform_query\"\n",
    "\n",
    "# Step 6: Build and Compile the Graph\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"grade_documents\", grade_documents)\n",
    "workflow.add_node(\"transform_query\", transform_query)\n",
    "workflow.add_node(\"web_searcher\", web_search)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "\n",
    "# Define edges\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\"grade_documents\", decide_to_generate, {\"transform_query\": \"transform_query\", \"generate\": \"generate\"})\n",
    "workflow.add_edge(\"transform_query\", \"web_searcher\")\n",
    "workflow.add_edge(\"web_searcher\", \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "# Display the graph\n",
    "display_graph(app, file_name=os.path.basename(__file__))\n",
    "\n",
    "# Example input\n",
    "inputs = {\"question\": \"Explain how the different types of agent memory work?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        pprint(f\"Node '{key}':\")\n",
    "        # Optional: print full state at each node\n",
    "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "    pprint(\"\\n---\\n\")\n",
    "\n",
    "pprint(value[\"generation\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
