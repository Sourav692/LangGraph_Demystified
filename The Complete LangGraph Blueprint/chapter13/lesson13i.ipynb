{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict, Literal\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, BaseMessage\n",
    "from pydantic import BaseModel\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Define RouteResponse for Customer Service Supervisor\n",
    "class RouteResponseCS(BaseModel):\n",
    "    next: Literal[\"Query_Agent\", \"Resolution_Agent\", \"Escalation_Agent\", \n",
    "                 \"FINISH\"]\n",
    "\n",
    "# Setup for Customer Service Supervisor\n",
    "members_cs = [\"Query_Agent\", \"Resolution_Agent\", \"Escalation_Agent\"]\n",
    "system_prompt_cs = f\"You are a Customer Service Supervisor managing agents: {', '.join(members_cs)}.\"\n",
    "\n",
    "# Create prompt template for the supervisor with correctly formatted options\n",
    "prompt_cs = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt_cs),\n",
    "    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    (\"system\", \"Choose the next agent to act from {options}.\"),\n",
    "]).partial(options=str(members_cs))\n",
    "\n",
    "# Define LLM and Supervisor function\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "def supervisor_agent_cs(state):\n",
    "    supervisor_chain_cs = prompt_cs | llm.with_structured_output(RouteResponseCS)\n",
    "    return supervisor_chain_cs.invoke(state)\n",
    "\n",
    "# Agent node function to handle message flow to each agent\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\n",
    "        \"messages\": [HumanMessage(content=result[\"messages\"][-1].content, \n",
    "                                name=name)]\n",
    "    }\n",
    "\n",
    "# Define agents for Customer Service tasks with realistic tools\n",
    "query_agent = create_react_agent(llm, tools=[TavilySearchResults(max_results=5)])\n",
    "resolution_agent = create_react_agent(llm, tools=[PythonREPLTool()])\n",
    "escalation_agent = create_react_agent(llm, tools=[PythonREPLTool()])\n",
    "\n",
    "# Create nodes for each agent with valid names\n",
    "query_node = partial(agent_node, agent=query_agent, name=\"Query_Agent\")\n",
    "resolution_node = partial(agent_node, agent=resolution_agent, \n",
    "                        name=\"Resolution_Agent\")\n",
    "escalation_node = partial(agent_node, agent=escalation_agent, \n",
    "                        name=\"Escalation_Agent\")\n",
    "\n",
    "# Define Customer Service graph state and workflow\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    next: str\n",
    "\n",
    "# Initialize StateGraph and add nodes\n",
    "workflow_cs = StateGraph(AgentState)\n",
    "workflow_cs.add_node(\"Query_Agent\", query_node)\n",
    "workflow_cs.add_node(\"Resolution_Agent\", resolution_node)\n",
    "workflow_cs.add_node(\"Escalation_Agent\", escalation_node)\n",
    "workflow_cs.add_node(\"supervisor\", supervisor_agent_cs)\n",
    "\n",
    "# Define edges for agents to return to the supervisor\n",
    "for member in members_cs:\n",
    "    workflow_cs.add_edge(member, \"supervisor\")\n",
    "\n",
    "# Define conditional map for routing\n",
    "conditional_map_cs = {k: k for k in members_cs}\n",
    "conditional_map_cs[\"FINISH\"] = END\n",
    "workflow_cs.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], \n",
    "                                conditional_map_cs)\n",
    "workflow_cs.add_edge(START, \"supervisor\")\n",
    "\n",
    "# Compile and test the graph\n",
    "graph_cs = workflow_cs.compile()\n",
    "\n",
    "# Example input for testing\n",
    "inputs_cs = {\"messages\": [HumanMessage(content=\"Help me reset my password.\")]}\n",
    "\n",
    "# Run the graph\n",
    "for output in graph_cs.stream(inputs_cs):\n",
    "    if \"__end__\" not in output:\n",
    "        print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
